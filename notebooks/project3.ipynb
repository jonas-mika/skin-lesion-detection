{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 3: Skin Lesion Detection in Medical Treatment using Machine Learning\n",
        "## Detecting Skin Cancer Type 'Melanoma' through Machine Learning\n",
        "---\n",
        "\n",
        "**Group 9: Aidan Stocks, Hugo Reinicke, Nicola Clark, Jonas-Mika Senghaas**\n",
        "\n",
        "Submission: *23.04.2021* / Last Modified: *22.04.2021*\n",
        "\n",
        "---\n",
        "\n",
        "This notebook contains the step-by-step data science process performed on the *ISIC 2017* public test data and official training data on medical image recognition. The goal of this project was to extract and automatically analyse features from medical images of skin lesions in order to predict whether or not the lesion is *melanoma* using image processing and machine learning classification algorithms.\n",
        "\n",
        "The initial data (containing the medical images, masked images and information on features and disease) was given for 150 medical images (equivalent to the public test data of the *ISIC 2017* challenge) by the project manager *Veronika *.\n",
        "To develop more accurate models, we extended the initially given data by the official training data that could be obtained from the official [ISIC 2017 Website](https://challenge.isic-archive.com/data). In a later part of the notebook, we will explain how to download the images for reproducing the results of this notebook."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00000-cb34c893-19b5-4eb7-bf5a-d02ead8d44fe",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "---\n",
        "When diagnosing the skin cancer **melanoma**, there are some key features doctors look for. Melanoma is typically: Asymmetrical, has an uneven Border, non-uniformly Colored, larger in Diameter than a pencil eraser, and can over time causing bleeding and other effects. This common guide for spotting melanoma is known as the ABCDE model.\n",
        "\n",
        "A quick search on mobile phone app stores will show dozens of different skin diagnosis apps, where a user can take a photo of their affected area of skin and get an unofficial diagnosis of what the condition could be. These apps calculate some of the aforementioned features from images to estimate a diagnosis. Medical imaging is also widely used to monitor and diagnose several conditions by medical professionals (*[Source](https://www.postdicom.com/en/blog/medical-imaging-science-and-applications)*). Thus there is great demand for machine learning algorithms to aid in diagnosing large volumes of such image data, thereby reducing the workload of doctors.\n",
        "\n",
        "This notebook contains all the code to explore the digital diagnosis process, by analysing images of skin lesions and using image processing and machine learning to attempt to accurately diagnose whether or not a lesion is melanoma. This formed the research question:\n",
        "\n",
        "> **To what degree of certainty can we predict if a patient has melanoma from a given medical image using machine learning?**\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00001-0c890553-5249-4dc4-b863-ecba0193daab",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running this Notebook\n",
        "---\n",
        "This notebook contains all code to reproduce the findings of the project as can be seen on the [GitHub](https://github.com/jonas-mika/fyp2021p03g09) page of this project. \n",
        "If one downloads the images used within this project, it is important that the global paths are correctly set. This can either be achieved through locally changing the file structure (ie. naming folders as defined in the notebook) or by adjusting the global variables within the `Constants` section of this notebook.\n",
        "\n",
        "*Note that the rest of the file structure as can be seen on the [GitHub](https://github.com/jonas-mika/fyp2021p03g09) page of the project generates automatically*"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00002-9d760373-d759-41b1-9739-48d3452591b9",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Libraries \n",
        "---\n",
        "Throughout the project, we will use a range of both built-in and external Python Libraries. This notebook will only run if all libraries and modules are correctly installed on your local machines. \n",
        "To install missing packages use `pip install <package_name>` (PIP (Python Package Index) is the central package management system, read more [here](https://pypi.org/project/pip/)). You can do this directly within the notebook by uncommenting the below cell.\n",
        "\n",
        "In case you desire further information about the used packages, click the following links to find detailed documentations:\n",
        "- [Pandas](https://pandas.pydata.org/)\n",
        "- [Numpy](https://numpy.org/)\n",
        "- [Matplotlib](https://matplotlib.org/stable/index.html)\n",
        "- [PIL](https://pillow.readthedocs.io/en/stable/)\n",
        "- [SciKit Learn](https://scikit-learn.org/stable/)\n",
        "- [SciKit Image](https://scikit-image.org/)\n",
        "- [Scipy](https://www.scipy.org/)\n",
        "- [ImbLearn](https://imbalanced-learn.org/stable/)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00003-6e74ab3c-05a2-47b0-95c8-bd85fea6fefc",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-54b6965a-fb79-43bd-b513-36fb8a2673bf",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a281805d",
        "execution_millis": 5929,
        "output_cleared": true,
        "execution_start": 1618999781334,
        "deepnote_cell_type": "code"
      },
      "source": [
        "%%capture \n",
        "# stop cell from displaying output\n",
        "\n",
        "# uncomment lines with uninstalled packages on local machine\n",
        "#!pip install scikit-image\n",
        "#!pip install imblearn\n",
        "#!pip install scikit-learn\n",
        "#!pip install pillow\n",
        "#!pip install itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-ce265327-d417-47b0-850b-6a4f0ab3a9cf",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3285c3db",
        "execution_millis": 3297,
        "output_cleared": true,
        "execution_start": 1618999796906,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# python standard libraries\n",
        "import os                                              # automates saving of export files (figures, summaries, ...)\n",
        "import re                                              # used for checking dateformat in data cleaning\n",
        "\n",
        "# external libraries\n",
        "import pandas as pd                                    # provides major datastructure pd.DataFrame() to store datasets\n",
        "import numpy as np                                     # used for numerical calculations and fast array manipulations\n",
        "import matplotlib.pyplot as plt                        # standard data visualisation\n",
        "import seaborn as sns                                  # convenient data visualisation\n",
        "from PIL import Image                                  # fork from PIL (python image library), image processing in python\n",
        "\n",
        "# specific functions\n",
        "import matplotlib.cm as cm\n",
        "from skimage import morphology\n",
        "#from scipy.stats.stats import mode\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.preprocessing import StandardScaler # normalise features\n",
        "from imblearn.under_sampling import RandomUnderSampler # balancing data\n",
        "from imblearn.over_sampling import RandomOverSampler # balancing data\n",
        "from imblearn.over_sampling import SMOTE # balancing data\n",
        "\n",
        "# feature selection\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest # univariate feature selection with mutual information for feature scoring\n",
        "from sklearn.feature_selection import SequentialFeatureSelector # sequential selection of k-features given fixed classifier \n",
        "\n",
        "# classifiers used in this project\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier # k-nearest neighbour classifier\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold  # producing equal cross-validation sets (reproducable results)\n",
        "from sklearn.model_selection import cross_val_score # perform cross-validation and report single metric\n",
        "from sklearn.model_selection import cross_validate # perform cross-validation and report set of metrics\n",
        "from sklearn.model_selection import GridSearchCV # perform cross-validation on given set of hyperparameters to find best hyperparamters optimising single metric\n",
        "from imblearn.pipeline import Pipeline, make_pipeline # balancing on each k-th training set in cross validation\n",
        "\n",
        "# evaluating model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Additional Data\n",
        "---\n",
        "The data analysis was performed on the concatenated data of the 150 initially given images and 2000 additional images obtained from the same data source - the [ISIC](https://challenge.isic-archive.com/data) (International Skin Imaging Collaboration) 2017 Competition. The links automatically start the download from the website - so be aware of clicking them, if no big downloads are intended.\n",
        "\n",
        "**REMARK: Not downloading the images will cause the image processing and feature extraction part of the notebook to not run properly. However, these sections can be skipped, by simply loading in the `feature.csv` dataframe that is provided in the submission**\n",
        "\n",
        "> Raw Data\n",
        "\n",
        ">> [Raw Data Images](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Data.zip)\n",
        "\n",
        ">> [Raw Data Masks](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Part1_GroundTruth.zip)\n",
        "\n",
        ">> [Raw Data Ground Truth](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Part3_GroundTruth.csv)\n",
        "\n",
        "> External Data\n",
        "\n",
        ">> [External Data Images](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Data.zip)\n",
        "\n",
        ">> [External Data Masks](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part1_GroundTruth.zip)\n",
        "\n",
        ">> [External Ground Truth](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part3_GroundTruth.csv)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00009-ab8c2759-432e-4819-be9d-80d303620266",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants\n",
        "---\n",
        "To enhance the readibilty, as well as to decrease the maintenance effort, it is useful for bigger projects to define contants that need to be accessed globally throughout the whole notebook in advance. \n",
        "The following cell contains all of those global constants. By convention, we write them in caps (https://www.python.org/dev/peps/pep-0008/#constants)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00008-8d4d4766-2724-4033-8584-15fe4722f493",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-b0a63da5-4fc5-41b4-86d4-5705799185d1",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "27b7344f",
        "execution_millis": 2,
        "output_cleared": true,
        "execution_start": 1618999811932,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# global parameters for running the notebooks (each computation )\n",
        "PREPROCESS_IMAGES = False\n",
        "COMPUTE_FEATURES = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-4e13d720-e857-4d9a-8abb-632aa8f19e3c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a1d98c23",
        "execution_millis": 7,
        "output_cleared": true,
        "execution_start": 1618999816931,
        "deepnote_cell_type": "code"
      },
      "source": [
        "PATH = {}\n",
        "PATH['data'] = {}\n",
        "PATH['data']['raw'] = \"../data/raw/\"\n",
        "PATH['data']['processed'] = \"../data/processed/\"\n",
        "PATH['data']['external'] = \"../data/external/\"\n",
        "\n",
        "PATH['images'] = 'images/'\n",
        "PATH['masks'] = 'masks/'\n",
        "PATH['filtered_images'] = 'filtered_images/'\n",
        "PATH['dummy_images']= 'dummy_images/'\n",
        "\n",
        "PATH['reports'] = \"../reports/\"\n",
        "\n",
        "# filename lookup dictionary storing the most relevant filenames\n",
        "FILENAME = {}\n",
        "FILENAME['diagnosis'] = 'diagnosis.csv' # changed from original name\n",
        "FILENAME['features'] = 'features.csv' # changed from original name\n",
        "\n",
        "# store filenames of different files in the project for easy iteration\n",
        "FILENAME['raw_images'] = sorted([image[:-4] for image in os.listdir(PATH['data']['raw'] + PATH['images']) if not re.match('.*super.*', image) and re.match('^ISIC', image)])\n",
        "FILENAME['raw_masks'] = sorted([mask[:-4] for mask in os.listdir(PATH['data']['raw'] + PATH['masks'])])\n",
        "FILENAME['external_images'] = sorted([image[:-4] for image in os.listdir(PATH['data']['external'] + PATH['images']) if not re.match('.*super.*', image)])[1:] # need to subscript because of weird dotfile\n",
        "FILENAME['external_masks'] = sorted([mask[:-4] for mask in os.listdir(PATH['data']['external'] + PATH['masks'])])\n",
        "FILENAME['all_images'] = sorted(FILENAME['raw_images'] + FILENAME['external_images'])\n",
        "FILENAME['all_masks'] = sorted(FILENAME['raw_masks'] + FILENAME['external_masks'])\n",
        "\n",
        "# defining main dictionaries to store data. each dictionary will reference different pd.DataFrames\n",
        "DATA = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 0**\n",
        "# Image Preprocessing\n",
        "---\n",
        "In this section we preprocess our image to make it nicer to deal with them in the later part of the project.\n",
        "\n",
        "1. Crop Images and Masks to be bound by lesion\n",
        "2. Make Width and Length an even number to be able to crop evenly\n",
        "3. Maybe save filtered image with color"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00013-3916c960-be31-476a-80d7-841da336db90",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00014-13f4e761-daae-49a7-acf7-41412d5e2a0f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "23a735da",
        "execution_millis": 0,
        "output_cleared": true,
        "execution_start": 1618981586076,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# helper function to make width and lengths even\n",
        "def make_even(img):\n",
        "    if img.size[0] % 2 != 0: #  making number of cols even\n",
        "        img = np.array(img)\n",
        "        mid = int(img.shape[1] / 2)\n",
        "        img = np.delete(img, mid, axis=1)\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    if img.size[1] % 2 != 0: # making number of rows even\n",
        "        img = np.array(img)\n",
        "        mid = int(img.shape[0] / 2)\n",
        "        img = np.delete(img, mid, axis=0)\n",
        "        img = Image.fromarray(img)\n",
        "    \n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00014-e8cc52ac-d501-404c-b8ab-f75edf0227d4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ad6ddc9e",
        "execution_millis": 0,
        "output_cleared": true,
        "execution_start": 1618981586453,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# preprocessing (170 seconds to run)\n",
        "if PREPROCESS_IMAGES == True:\n",
        "    try: \n",
        "        os.makedirs(PATH['data']['processed'] + PATH['images'])\n",
        "        os.makedirs(PATH['data']['processed'] + PATH['masks'])\n",
        "        os.makedirs(PATH['data']['processed'] + PATH['filtered_images'])\n",
        "    except: print('Directories already exist.')\n",
        "\n",
        "    print('Starting Preprocessing of Raw Images...')\n",
        "    for i in range(150):\n",
        "        # get image names\n",
        "        img_name = FILENAME['raw_images'][i] + '.jpg'\n",
        "        mask_name = FILENAME['raw_masks'][i] + '.png'\n",
        "\n",
        "        # open temporarily\n",
        "        img = Image.open(PATH['data']['raw'] + PATH['images'] + img_name)\n",
        "        mask = Image.open(PATH['data']['raw'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        # crop to only store lesion\n",
        "        cropped_img = img.crop(mask.getbbox())\n",
        "        cropped_mask = mask.crop(mask.getbbox())\n",
        "\n",
        "        # make width and length even (two cases)\n",
        "        cropped_img = make_even(cropped_img)\n",
        "        cropped_mask = make_even(cropped_mask)\n",
        "\n",
        "        # create filtered with color\n",
        "        dummy = Image.new(\"RGB\", cropped_img.size, 0)\n",
        "        filtered_img = Image.composite(cropped_img, dummy, cropped_mask)\n",
        "        \n",
        "        # save to '../data/processed' in correct subfolder\n",
        "        cropped_img.save(PATH['data']['processed'] + PATH['images'] + img_name)\n",
        "        cropped_mask.save(PATH['data']['processed'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        filtered_img.save(PATH['data']['processed'] + PATH['filtered_images'] + img_name)\n",
        "\n",
        "    print('Processed Raw-Data\\n')\n",
        "    print('Starting Preprocessing of External Images...')\n",
        "\n",
        "    for i in range(2000):\n",
        "        # get image names\n",
        "        img_name = FILENAME['external_images'][i] + '.jpg'\n",
        "        mask_name = FILENAME['external_masks'][i] + '.png'\n",
        "\n",
        "        # open temporarily\n",
        "        img = Image.open(PATH['data']['external'] + PATH['images'] + img_name)\n",
        "        mask = Image.open(PATH['data']['external'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        # crop to only store lesion\n",
        "        cropped_img = img.crop(mask.getbbox())\n",
        "        cropped_mask = mask.crop(mask.getbbox())\n",
        "\n",
        "        # make width and length even (two cases)\n",
        "        cropped_img = make_even(cropped_img)\n",
        "        cropped_mask = make_even(cropped_mask)\n",
        "\n",
        "        # create filtered with color\n",
        "        dummy = Image.new(\"RGB\", cropped_img.size, 0)\n",
        "        filtered_img = Image.composite(cropped_img, dummy, cropped_mask)\n",
        "        \n",
        "        # save to '../data/processed' in correct subfolder\n",
        "        cropped_img.save(PATH['data']['processed'] + PATH['images'] + img_name)\n",
        "        cropped_mask.save(PATH['data']['processed'] + PATH['masks'] + mask_name)\n",
        "        filtered_img.save(PATH['data']['processed'] + PATH['filtered_images'] + img_name)\n",
        "        \n",
        "        \n",
        "    print('Preprocessing Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 0.5*\n",
        "# Data Exploration\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00010-94b50f7c-6711-4349-bbfc-c11ba8d47de0",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in Data\n",
        "\n",
        "---\n",
        "\n",
        "The task involves different sources of data, namely:\n",
        "\n",
        "> **Images**: 150 initially given medical images of skin lesions + 2000 externally obtained images of the same format.\n",
        "\n",
        "> **Masks**: 150 initially given binary masks, specificying the region of the skin lesion + 2000 externally obtained masks of the same format.\n",
        "\n",
        "> **Diagnosis**: Dataset storing whether or not the lesion was either *melanoma*, *seborrheic_keratosis* or *neither* through binary values.\n",
        "\n",
        "We conveniently load in the raw and external *diagnosis* dataset into individual `pd.DataFrames` using the built-in pandas method `pd.read_csv()`. We store those in our `DATA` dictionary in the corresponding keys and concatenate them, to have one central diagnosis dataframe holding all 2150 diagnoses. \n",
        "\n",
        "For saving RAM, neither the *images* nor the *masks* are read in locally into the script, but instead read in one-by-one from the file system, whenever they are needed."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00011-b337fa92-d698-471c-bc5b-f941c1aef692",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "b623e53d",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-2900529b-7a4b-4fce-bc3c-11beff12d811",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e604c12e",
        "execution_millis": 15,
        "output_cleared": true,
        "execution_start": 1618999822838,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# load in raw and external dataset from different paths\n",
        "DATA['raw_diagnosis'] = pd.read_csv(PATH['data']['raw'] + FILENAME['diagnosis']) # 150 x 3\n",
        "DATA['external_diagnosis'] = pd.read_csv(PATH['data']['external'] + FILENAME['diagnosis']) # 2000 x 3\n",
        "\n",
        "# concatenate into big dataframe\n",
        "DATA['diagnosis'] = pd.concat([DATA['raw_diagnosis'], DATA['external_diagnosis']], ignore_index=True).sort_values(by=['image_id']) # 2150 x 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspection of Dataset (Target Variable)\n",
        "\n",
        "---\n",
        "\n",
        "The *diagnosis* dataset contains our target variable - the binary label *melanoma* or *not melanoma*. \n",
        "In this section we get some first understanding of the frequency of our target label in the data, which will play an important role when developing the machine learning model.\n",
        "\n",
        "We start by reporting the number of records and fields/ variables in the dataset by using the shape property of the `pd.DataFrame`. We then continue to have an actual look into the data. Similiar to the head command in terminal, we can use the method `head()` onto our DataFrames, which outputs an inline representation of the first five data records of the dataset.\n",
        "We then visualise the frequency distribution of the three possible labels within the data."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00015-bc508507-98dd-4277-95d2-820a3765f909",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00016-d2dacc61-945c-4362-8d5d-474ff69ead14",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00015-061506db-72d9-42ea-8d71-96b100252925",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "cf497bf3",
        "execution_millis": 14,
        "output_cleared": false,
        "execution_start": 1618999831092,
        "deepnote_cell_type": "code"
      },
      "source": [
        "print(f\"Diagnosis: {DATA['diagnosis'].shape}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diagnosis Dataset**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00019-32045793-8a8c-4aae-a08f-8a8d0c8482e6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00020-46b4d62f-7504-43ed-9415-48567333d4fb",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "8e901a74",
        "execution_millis": 40,
        "output_cleared": false,
        "execution_start": 1618999831911,
        "deepnote_cell_type": "code"
      },
      "source": [
        "DATA['diagnosis'].head() # confirm its sorted"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00025-19369e86-c8a2-44c4-982f-5ce5a8148e3f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "881eae63",
        "execution_millis": 172,
        "output_cleared": true,
        "execution_start": 1618999832564,
        "deepnote_cell_type": "code"
      },
      "source": [
        "%%capture\n",
        "# extract cols\n",
        "mel = DATA['diagnosis']['melanoma']\n",
        "ker = DATA['diagnosis']['seborrheic_keratosis']\n",
        "\n",
        "# mask all cases\n",
        "mel_mask = (mel == 1) & (ker == 0)\n",
        "ker_mask = (mel == 0) & (ker == 1)\n",
        "neither_mask = (mel == 0) & (ker == 0)\n",
        "both_mask = (mel == 1) & (ker == 1)\n",
        "\n",
        "# append 3-class label into 'diagnosis' col\n",
        "DATA['diagnosis']['diagnosis'] = 0\n",
        "for i in range(DATA['diagnosis'].shape[0]):\n",
        "    if mel_mask[i]: DATA['diagnosis']['diagnosis'].loc[i] = 2\n",
        "    elif ker_mask[i]: DATA['diagnosis']['diagnosis'].loc[i] = 1\n",
        "    else: DATA['diagnosis']['diagnosis'].loc[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00022-0c9e3f29-3e98-440d-99b0-d600fc63f164",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a3ce5907",
        "execution_millis": 301,
        "output_cleared": false,
        "execution_start": 1618999834930,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# distribution of diagnosis\n",
        "diagnosis, counts = np.unique(DATA['diagnosis']['diagnosis'], return_counts=True)\n",
        "\n",
        "for x in range(len(diagnosis)):\n",
        "    print(f\"{diagnosis[x]}: {counts[x]}\")\n",
        "\n",
        "# plot\n",
        "fig,ax = plt.subplots()\n",
        "ax.bar(diagnosis, counts, color='gray')\n",
        "# maybe add text with numeric count\n",
        "ax.set_title('Distribution of Diagnosis', fontweight='bold'); ax.set_xlabel('Diagnosis', fontstyle='italic'); ax.set_ylabel('Frequency', fontstyle='italic');\n",
        "ax.set_xticks(diagnosis); ax.set_xticklabels(['Neither', 'Keratosis', 'Melanoma']);"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority (~67%) of the recorded skin lesions were neither *melanoma* nor *non-melanoma*. Only ~14% were *keratosis* and ~19% were *melanoma*.\n",
        "\n",
        "This significant imbalance is important to keep in mind, when building our model, as high class imbalance, makes machine learning models often biased towards rigoursly detecting the dominating the label - result in high accuracy scores, but 0 sensitivity.\n",
        "\n",
        "Furthermore, the visualisation reveals that he two diseases are - as expected - mutually exclusive, meaning that a single skin lesion cannot be diagnosed with multiple diseases."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00026-e5b563ed-0d60-4d37-ac09-3cc0a1505f27",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspection of Images\n",
        "---\n",
        "The main part of the project is to analyse medical images for a set of features. To do so, we can analyse both the original image and a binary mask. In this section, we will look at examples of images and their corresponding mask to get a feel for the type of images we are dealing with and assess the quality of the masks."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00022-74d262e9-0785-418b-a633-7e5351b05a1e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00023-98a3e227-2bf8-417a-80a6-b3badc4edf43",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "759b8a1",
        "execution_millis": 2586,
        "output_cleared": false,
        "execution_start": 1618999853711,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# load test image using PIL\n",
        "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(15,15))\n",
        "fig.suptitle('Examples of Images and Corresponding Masks', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i in range(3):\n",
        "    ex_img = Image.open('../data/processed/images/' + FILENAME['all_images'][i] + '.jpg')\n",
        "    ex_img_mask = Image.open('../data/processed/masks/' + FILENAME['all_masks'][i] + '.png')\n",
        "\n",
        "    ax[i][0].imshow(ex_img)\n",
        "    ax[i][0].set_xlabel(f\"{ex_img.format}, {ex_img.size}, {ex_img.mode}\");\n",
        "    ax[i][1].imshow(ex_img_mask, cmap='gray')\n",
        "    ax[i][1].set_xlabel(f\"{ex_img_mask.format}, {ex_img_mask.size}, {ex_img_mask.mode}\");\n",
        "\n",
        "ax[0][0].set_title('Medical Image');\n",
        "ax[0][1].set_title('Corresponding Binary Mask');\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "The initially given high-resolution images (often 3000X2000px) were sucessfully cut down in size within our preprocessing to only display the part of the image that is relevant for our analysis and decrease running times of feature computation and training of models. Furthermore, all images and masks were modified in a way that all images and masks have an even width and length, which is necessary to correctly compute the asymmetry score in a later section. \n",
        "\n",
        "From the three sampled pictures, it generally appears that the masks give a well-enough approximation of the actual shape of the lesion. However, they do seem to differ in the way they were computed, as some smoothen out borders more than others. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 1*\n",
        "# Extracting Features \n",
        "\n",
        "---\n",
        "\n",
        "We need to find quantitative measures of how to best classify *melanoma*. The following handcrafted features are assessed during this project:\n",
        "\n",
        "> **Compactness**. A quantitative measure of the shape of the lesion. The smaller the value, the more compact the lesion is. A perfect circle has a compactness score of roughly 1.\n",
        "\n",
        "> **Average Luminance**. A quantitative measure of the averaged brightness of the lesion. The higher the value, the lighter the lesion, and vice versa. Values range from 0 (meaning 100% black) to 255 (meaning 100% white).\n",
        "\n",
        "> **Luminance Variability**. A quantitative measure to determine the variation of luminance of the lesion. The higher the value, the more variation can be found on the lesion. \n",
        "\n",
        "> **Average Colour**. A quantitative measure of the averaged colour of the lesion. This metric is split up inthe the average color in the three RGB channels individually. Each ranges between 0 and 255.\n",
        "\n",
        "> **Colour Variability**. A quantitative measure to determine the variation of color of the lesion. The higher the value, the more variation can be found on the lesion. output in the format of (rvariation,gvariation,bvariation),average variation\n",
        "\n",
        "> **Asymmetry**. A quantitative measure to assess the symmetry of the lesion. Measured through relative number of non-overlapping pixels in different rotations. The higher the value, the less symmmetric the lesion is. A perfect circle, should score a 0 asymmetry score."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00011-2f24366e-2e6e-4fb6-bd80-8420bbf40dde",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for Feature Extraction"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00032-577c1d3c-aca3-4b53-b527-01781d1e819a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00033-50ce0ba4-6e2a-4f83-9209-da3d252a2ab3",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ef3eec4d",
        "execution_millis": 0,
        "output_cleared": true,
        "execution_start": 1618999888016,
        "deepnote_cell_type": "code"
      },
      "source": [
        "def measure_area_perimeter(mask):\n",
        "    # Measure area: the sum of all white pixels in the mask image\n",
        "    mask = np.where(np.array(mask)==255, 1, 0)\n",
        "    \n",
        "    # compute area as number of white pixels \n",
        "    area = np.sum(mask)\n",
        "\n",
        "    # compute perimeter by eroding 1 pixel from mask and then compute the difference between original and eroded mask\n",
        "    struct_el = morphology.disk(1)\n",
        "    mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
        "    image_perimeter = mask - mask_eroded\n",
        "    perimeter = np.sum(image_perimeter)\n",
        "    \n",
        "    return area, perimeter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00029-d9616ba2-826f-40c2-8d07-5d8ab8fd7c5e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b436d025",
        "execution_millis": 5,
        "output_cleared": true,
        "execution_start": 1618999888783,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# compactness\n",
        "def get_compactness(mask):\n",
        "    area, perimeter = measure_area_perimeter(mask)\n",
        "    # return compactness formula\n",
        "    return ( ( perimeter ** 2) / (4 * np.pi * area ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00028-ef906370-e43a-41aa-90d7-aa44d8cf16fe",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ba4da5b5",
        "execution_millis": 6,
        "output_cleared": true,
        "execution_start": 1618999889269,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# average luminance\n",
        "def get_average_luminance(filtered_image): # image needs to be filtered for lesion\n",
        "    gray = np.array(filtered_image.convert('L')) # converting to gray scale \n",
        "    return round(np.mean(gray[gray > 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00042-54d6c44d-ae8c-4362-ad59-6e7e30c06b71",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e39f82f",
        "execution_millis": 12,
        "output_cleared": true,
        "execution_start": 1618999889756,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# luminance variability\n",
        "def get_luminance_variability(filtered_image, measure='variance'):\n",
        "    gray = np.array(filtered_image.convert('L')) # converting to gray scale \n",
        "    if measure == 'variance': return round(np.var(gray[gray > 0]))\n",
        "    elif measure == 'standard_deviation': return round(np.std(gray[gray > 0]))\n",
        "    else: print('Cannot compute this `measure`. Try `variance` or `standard_deviation`')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00056-68ee87e3-71b4-493a-b296-a58f9365fcda",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a9eb3fdc",
        "execution_millis": 5,
        "output_cleared": true,
        "execution_start": 1618999893143,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# average color\n",
        "def get_average_color(filtered_image): # image needs to be filtered for lesion\n",
        "    r, g, b = filtered_image.split() # converting to separate channels  \n",
        "    r= np.array(r) \n",
        "    g= np.array(g)\n",
        "    b= np.array(b) \n",
        "    return [round(np.mean(r[r > 0])),round(np.mean(g[g > 0])),round(np.mean(b[b > 0]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00043-e14402fc-ca64-4234-8d4d-9c6a06ddfcb8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d728f987",
        "execution_millis": 21,
        "output_cleared": true,
        "execution_start": 1618999894117,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# color variability\n",
        "def get_color_variability(filtered_image, measure='variance'): # image needs to be filteredd for lesion\n",
        "    r, g, b = filtered_image.split() # converting to separate channels  \n",
        "    r= np.array(r) \n",
        "    g= np.array(g)\n",
        "    b= np.array(b) \n",
        "    if measure == 'variance': rgb=(np.var(r[r > 0]),np.var(g[g > 0]),np.var(b[b > 0]))\n",
        "    elif measure == 'standard_deviation': rgb=(np.std(r[r > 0]),np.std(g[g > 0]),np.std(b[b > 0]))\n",
        "    else: return \n",
        "    return np.mean(rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00038-30509f12-2361-4e03-804c-cdc34f4aea6f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1dbe74ba",
        "execution_millis": 7,
        "output_cleared": true,
        "execution_start": 1618999900075,
        "deepnote_cell_type": "code"
      },
      "source": [
        "def get_asymmetry(mask):\n",
        "    return round(np.mean([asymmetry(mask), asymmetry(mask.rotate(90, expand=True))]),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00030-7ee66c85-2792-4ad4-935f-dfc3e8257a30",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ce804e57",
        "execution_millis": 4,
        "output_cleared": true,
        "execution_start": 1618999900459,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# helper for asymmetry\n",
        "def asymmetry(mask):\n",
        "    # calculate basic properties of image\n",
        "    width, length = mask.size  # requires even number of pixels in both dimensions\n",
        "    size = width * length\n",
        "\n",
        "    if width%2!=0:\n",
        "        print(\"Uneven Number of Pixels. Can't calculate asymmetry.\")\n",
        "\n",
        "    # cut in half and fold\n",
        "    left = mask.crop((0,0,(width/2), length)) \n",
        "    right = mask.crop((width/2,0,width,length))\n",
        "    right = right.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "    # get binary array of unequal positions (the closer the sum to 0, the better the symmetry)\n",
        "    diff = np.where(np.array(left) != np.array(right), 1, 0)\n",
        "\n",
        "    return np.sum(diff) / (size / 2) # percentage of asymmetric pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Feature Extraction\n",
        "---\n",
        "\n",
        "Before accepting our functions to compute the featurs as universal truth, we need to test them on a set of dummy images, for which we know what metrics we are expecting. If the computed values of our functions match with the expectation, it is reasonable to believe that the functions indeed compute the desired feature."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00055-1858f146-2046-4965-b2cc-f966cab2caf6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00042-1eae9862-d608-44ec-b89e-54ecf331b7b9",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "31dd0608",
        "execution_millis": 2379,
        "output_cleared": false,
        "execution_start": 1618999904924,
        "deepnote_cell_type": "code"
      },
      "source": [
        "dummies = ['dummy' + str(i+1) for i in range(2)]\n",
        "\n",
        "# show dummy image and mask\n",
        "fig, ax = plt.subplots(nrows=len(dummies), ncols=2, figsize=(16, 6 * len(dummies)))\n",
        "fig.suptitle(\"Feature Extration on Dummies\", fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, img_name in enumerate(dummies):\n",
        "    # compute features\n",
        "    img = Image.open('../data/external/dummy_images/' + img_name + '.jpg')\n",
        "    img_mask = Image.open('../data/external/dummy_images/' + img_name + '_mask.png').convert('L')\n",
        "\n",
        "    area, perimeter = measure_area_perimeter(img_mask)\n",
        "    compactness = get_compactness(img_mask)\n",
        "    asymmetry_score = get_asymmetry(img_mask)\n",
        "    average_luminance = get_average_luminance(img)\n",
        "    luminance_variance = get_luminance_variability(img)\n",
        "    average_colors = get_average_color(img)\n",
        "    color_variance = get_color_variability(img)\n",
        "\n",
        "    # print out computed features\n",
        "    print('#'*15 + f\"   Dummy {i+1}   \" + '#'*15)\n",
        "    print(f\"Area / Perimeter      : {area}px / {perimeter}px\")\n",
        "    print(f\"Compactness           : {compactness}\")\n",
        "    print(f\"Asymmetry             : {asymmetry_score * 100}%\")\n",
        "    print(f\"Average Luminance     : {average_luminance}\")\n",
        "    print(f\"Luminance Variance    : {luminance_variance}\")\n",
        "    print(f\"Average Colors (RGB)  : {average_colors}\")\n",
        "    print(f\"Color Variability     : {color_variance}\\n\")\n",
        "\n",
        "    ax[i][0].imshow(img);\n",
        "    ax[i][1].imshow(img_mask, cmap='gray');\n",
        "    ax[i][0].set_title(f'Dummy {i+1}', fontsize=10, fontstyle='italic')\n",
        "    ax[i][1].set_title(f'Dummy {i+1} Mask', fontsize=10, fontstyle='italic')\n",
        "    ax[i][0].set_xlabel(f'{img.format}, {img.size}, {img.mode}', fontstyle='italic');\n",
        "    ax[i][1].set_xlabel(f'{img_mask.format}, {img_mask.size}, {img_mask.mode}', fontstyle='italic');"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "**Evaluation**\n",
        "\n",
        "> *Compactness*: A perfect circle should have a lower compactnes score (and is thusly more compact), than the triangle. This is indeed computed by our `get_compactness()` function.\n",
        "\n",
        "> *Asymmetry*: A perfect circle shouldn't be asymmetric accross the two main axes, and thusly a asymmetry score of 0%, whereas the triangle should report a higher value, since the second fold is asymmetric. This is indeed computed by our `get_asymmetry()` function.\n",
        "\n",
        "> *Average Luminance*: We expect the red-gradient circle to have a higher average luminance than the dark grey triangle. This is indeed computed by our `get_average_luminance()` function.\n",
        "\n",
        "> *Luminance Variance*: We expect the gradient circle to have a higher variance in the luminance than the uniformly colored triangle. This is indeed computed by our `get_luminance_variability()` function.\n",
        "\n",
        "> *Average Color*:  We expect the red-gradient circle to have a high average color value in the red-channel and a lower in the remaining two, whereas the uniformly grey-colored triangle is expected to have equal values in all three channels. This is indeed computed by our `get_average_color()` function.\n",
        "\n",
        "> *Color Variability*: We expect the gradient circle to have a higher variance amongst all three color channels than the uniformly colored triangle. This is indeed computed by our `get_color_variability()` function."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Features\n",
        "---\n",
        "\n",
        "We have developed our functions to extract features from the medical images of the lesions and have proven them to work on dummy images, where we were able to validate assumed scores in each feature. We can therefore now compute the features for each image and append it to our main dataframe to store the data, that is later used to train our model. \n",
        "\n",
        "At the end of the cell, a pd.Dataframe called `DATA['features']` is computed, which holds the Image ID, all eight computed features and the diagnosis for each image. \n",
        "\n",
        "*Note*: If the `COMPUTE_FEATURES` variable is set to `False` (to save roughly 8min of computation), the already computed dataframe is read in from the file structure."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00053-e69f91a1-e003-4880-bc8e-9ccdc2a51e04",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00059-ff38722b-dbe7-43fd-85ea-453cf62b1180",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2d7e6f16",
        "execution_millis": 1,
        "output_cleared": true,
        "execution_start": 1619000224638,
        "deepnote_cell_type": "code"
      },
      "source": [
        "features = ['compactness', 'average_luminance', 'luminance_variability', 'average_red', 'average_green', 'average_blue', 'color_variability', 'asymmetry']\n",
        "\n",
        "feature_functions = {\n",
        "    'compactness': get_compactness,\n",
        "    'average_luminance': get_average_luminance,\n",
        "    'luminance_variability': get_luminance_variability,\n",
        "    'average_red': get_average_color,\n",
        "    'average_green': get_average_color,\n",
        "    'average_blue': get_average_color,\n",
        "    'color_variability': get_color_variability,\n",
        "    'asymmetry': get_asymmetry\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00054-4dafbcbe-8adc-43ff-942e-82502bfbf355",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ff8e3abd",
        "execution_millis": 107882,
        "output_cleared": true,
        "execution_start": 1619000225591,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# compute all features (execution time: >8min)\n",
        "if COMPUTE_FEATURES == True:\n",
        "    feature_dict = {feature: [] for feature in features}\n",
        "\n",
        "    for i in range(len(FILENAME['all_images'])):\n",
        "        name = FILENAME['all_images'][i]\n",
        "        img_name = FILENAME['all_images'][i] + '.jpg'\n",
        "        mask_name = FILENAME['all_masks'][i] + '.png'\n",
        "\n",
        "        # open temporarily\n",
        "        filtered_img = Image.open(PATH['data']['processed'] + PATH['filtered_images'] + img_name)\n",
        "        mask = Image.open(PATH['data']['processed'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        # measure features and append to feature_dict\n",
        "        for feature in features:\n",
        "            if feature in ['compactness', 'asymmetry']:\n",
        "                feature_dict[feature].append(feature_functions[feature](mask))\n",
        "            elif feature in ['average_luminance', 'luminance_variability', 'color_variability']:\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img))\n",
        "            elif feature == 'average_red':\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img)[0])\n",
        "            elif feature == 'average_green':\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img)[1])\n",
        "            elif feature == 'average_blue':\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img)[2])\n",
        "        \n",
        "    # append extracted features and diagnosis to features.csv\n",
        "    DATA['features'] = pd.DataFrame({'id': FILENAME['all_images']})\n",
        "    DATA['features'] = pd.concat([DATA['features'], pd.DataFrame(feature_dict), DATA['diagnosis'][['melanoma', 'seborrheic_keratosis', 'diagnosis']]], axis=1) # concatenating handcrafted features and diagnosis\n",
        "\n",
        "    # save all computed features\n",
        "    DATA['features'].to_csv(PATH['data']['processed'] + 'features.csv')\n",
        "\n",
        "else: DATA['features'] = pd.read_csv(PATH['data']['processed'] + 'features.csv').iloc[: , 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Main DataFrame\n",
        "---\n",
        "Check that the computation or reading in of the dataframe was successful, by displaying it inline in Jupyter."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00054-91ebedfb-45da-4415-a8a8-795538fbefa6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00060-344598b0-1f7c-4353-997d-46f4c12178aa",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4c274380",
        "execution_millis": 110,
        "output_cleared": false,
        "execution_start": 1619000764532,
        "deepnote_cell_type": "code"
      },
      "source": [
        "DATA['features']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 1.5*\n",
        "# Evaluate Features for Classification\n",
        "---\n",
        "\n",
        "In this section, we are plotting the handcrafted features in order to see, whether any correaltions appear. Since we are trying to classify a binary label, namely whether a lesion is diseased with *melanoma* or not, we plot the distribution of each feature in the two classes *melanoma* and *no melanoma* to get a visual intuition of how good the specific feature might be able to distinguish between our target label. \n",
        "The more distinct the two distributions are, the better the feature will be at prediciting the tartget value."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00053-69c9fc88-3be3-4112-8c01-f0dbb64ad41a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visual Exploration"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00062-7e6b9ce6-6d64-4bad-9689-2e22cb93bfbf",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00056-59589987-30e3-42b4-b59a-04f452c8a344",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "bb95ba7a",
        "execution_millis": 1807,
        "output_cleared": true,
        "execution_start": 1618981735158,
        "deepnote_cell_type": "code"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=len(features), figsize=(8, 6 * len(features)))\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    sns.violinplot(x='melanoma', \n",
        "                   y=feature, \n",
        "                   data=DATA['features'],  \n",
        "                   ax=ax[i]).set_title(f\"Distribution of {feature.title().replace('_', ' ')} in Different Classes\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00067-14466d2a-d096-4e81-a4d6-25b9d15b5e50",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "6af9874d",
        "execution_millis": 47781,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": [
        "sns.pairplot(DATA['features'], hue='melanoma', height=2, diag_kind=\"hist\"); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 2*\n",
        "# Predict Diagnosis\n",
        "\n",
        "---\n",
        "\n",
        "We have 'handcrafted' a number of features and now aim to find the model that is the most robust to predict our target variable - whether the lesion is our is not diseased with melanoma. In the process of doing so, a number of questions arise that we will step-by-step tackle in order to build the 'best' model. \n",
        "\n",
        "> **Performance Metrics**: Which metrics do we use to assess whether or not our model does good?\n",
        "\n",
        "> **Defining Features and Target Variable**: Which label are we trying to predict and what features do we have at hand to do so?\n",
        "\n",
        "> **Train-Test Split**: How can we get scores that resemble the model's performance on real out-of-sample data?\n",
        "\n",
        "> **Normalisation**: How do we make sure that each feature contributes equally to the model's prediction?\n",
        "\n",
        "> **Selecting Features**: Which (combination of) features are (/is) likely do perform best?\n",
        "\n",
        "> **Building Model**: Which model (and with which hyperparameters) does best in achieving the desired performance?"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00012-7fd9c2d5-6342-493a-af45-dc85efb4d664",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "source": [
        "## Performance Metrics\n",
        "---\n",
        "\n",
        "Choosing performance metrics is arguably a design choice for the model, and different approaches are surely possible. For the purpose of this ML model, which detects a minority class, we chose to go with the widely used metric of `Recall`, which measures the *sensitivity* of the model towards detecting positives (The percentage of positives that were detected by the model). \n",
        "That is, because in medical diagnosis detecting false positives is generally more acceptable than false negatives, since the latter could potentially result into serious diseases."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Initial Features and Target Variable\n",
        "---\n",
        "First, we need to define from which set of features our model should choose the ones that are likely to perform best on a specified target variable. \n",
        "In our case, each measured feature is potentially interesting for the model, and we want to predict the binary label, whether or not the classifier is diseased with *melanoma* or not.\n",
        "\n",
        "By, convention, we call the feature matrix `X` and the target column `y`."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00067-01107798-cc24-4632-a815-3423c563b1f0",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = DATA['features'][features]\n",
        "y = DATA['features'][['melanoma']]"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00068-a4ea27ed-35f8-42a1-8ce0-beed82d2528b",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1274c265",
        "execution_millis": 5,
        "output_cleared": true,
        "execution_start": 1619001396722,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split\n",
        "---\n",
        "Before, we doing anything further with our data, we split our data into a `development` set and a `test` set. The test set will be used to assess the final performance of the model by mimicing a true *out-of-sample* set of datapoints. For this project, we chose a standard split size of `0.3`, meaning that 30% of the original data will be used for testing, and 70% for the development of the model.\n",
        "\n",
        "We split the data at this early stage to not bias our model towards the test dataset, ie. performing the feature selection, normalisation or balancing process on all of the data, might bias it towards the test data, and thus result in a sligthly overfitted model, that might perform good on the test, but not in real-life. \n",
        "\n",
        "*Note: Whenever there is randomness involved, we set `random_state=1` to produce reproducable results.*"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00065-dc7dbdd2-dbd1-4a7d-a7e8-9f93e056de62",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into dev-test data (hold-out data to mimic true 'out-of-sample' data)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00066-81016beb-b954-4925-a39e-26939fbbc303",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "511c379a",
        "execution_millis": 1,
        "output_cleared": true,
        "execution_start": 1619001927120,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_dev.shape, y_dev.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalisation\n",
        "---\n",
        "Our measured handcrafted features all perform on different scales, ie. the *average luminance* can only obtain values between 0 and 255, whereas the *asymmetry* is the average percentage of non-matching pixels in two-folds of the image.\n",
        "\n",
        "Since we want each of our features to equally contribute to the prediction of the model, we need to normalise them. We do this through the formula of the standard score $\\frac{x-\\mu}{\\sigma}$ ([Wikipedia](https://en.wikipedia.org/wiki/Standard_score)). We computed the values for the normalisation solely on the development set (again, to not bias the model towards the test data) and then use this scaling to scale both the development and test features matrices. Within the whole process the target column (the binary label 0 and 1), is not scaled.\n",
        "\n",
        "We can easily use `sklearn`'s `StandardScaler`, which does the job for us."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00077-b097ada6-58a9-40c9-90ca-d8dcbad7434a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of features after normalisation\n",
        "plt.figure(figsize=(15,5));\n",
        "sns.boxplot(data=X_dev, width=0.5);"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00072-d68daeff-2cd4-4673-8d0f-997340d766de",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "5fba9c86",
        "execution_millis": 536,
        "output_cleared": false,
        "execution_start": 1619001428586,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(X_dev) # (x - mu) / std\n",
        "X_dev = pd.DataFrame(scaler.transform(X_dev), columns=features)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=features)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00078-c08a7e1c-a0ee-4d29-9ea6-3ee1b70ea292",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "41bfd634",
        "execution_millis": 12,
        "output_cleared": true,
        "execution_start": 1619001427490,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of features before normalisation\n",
        "plt.figure(figsize=(15,5));\n",
        "sns.boxplot(data=X_dev, width=0.5);"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00070-1542bccc-2f57-49fb-b39d-f1844e915367",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6444a681",
        "execution_millis": 519,
        "output_cleared": false,
        "execution_start": 1619001398505,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "## Balancing Data\n",
        "---\n",
        "As we have seen in the initial exploration of the data, the labels are heavily imbalanced. Out of the 150 observed images, only 30 are diseased with *melanoma*, which results in precisely 20% of the data. If we would naively train our model disregarding the imbalance and only evaluate the model's performance by its *accuracy score*, we are likely to see a model performing equally or very similar to the so-called *null-hypotheses* (always predicting the dominating label), which would lead to a 80% accuracy in our case. \n",
        "\n",
        "To prevent this we balance our data, such that at the end of the process the data we train our model has equal amounts of *melanoma* and *not melanoma*.\n",
        "There are two ways of doing this:\n",
        "\n",
        "> **Random Undersampling**: Cutting down the frequency of the dominant label.\n",
        "\n",
        "> **Random Oversampling**: Duplicating the less dominant feature.\n",
        "\n",
        "Although, both option are obviously not ideal (since we loose information in the first, and create duplicate information in the second), and we would always prefer a orginally balanced dataset, we need to make a choice. For this project, we *upsampled* our data, since undersampling, would have limited our whole analyis to only 60 images, which is likely to not create an accurate model.\n",
        "\n",
        "We oversample using `imblearn`'s class `RandomOverSampler`.\n",
        "\n",
        "> **REMARK:** As we will later see, estimating the model's performance by cross-validating on an oversampled development set, produces highly overconfident scores. Correct upsampling, is therefore done by iteratively upsampling for each k-fold during the cross-validation, to create unbiased results. This is shown in detail in a later section."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot before oversampling\n",
        "fig, axes = plt.subplots(ncols=3, figsize=(12, 3))\n",
        "for ax, dataset in zip(axes, [y, y_dev, y_test]):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    ax.bar(unique, counts); ax.set_xticks([1,0])\n",
        "axes[0].set_title('Target Imbalance on `y`');\n",
        "axes[1].set_title('Target Imbalance on `y_dev`');\n",
        "axes[2].set_title('Target Imbalance on `y_test`');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# balance data (using over-sampling)\n",
        "oversampler = RandomOverSampler(random_state=1)\n",
        "X_dev_sampled, y_dev_sampled = oversampler.fit_resample(X_dev, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot after oversampling\n",
        "fig, axes = plt.subplots(ncols=3, figsize=(12, 3))\n",
        "for ax, dataset in zip(axes, [y, y_dev_sampled, y_test]):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    ax.bar(unique, counts); ax.set_xticks([1,0])\n",
        "axes[0].set_title('Target Imbalance on `y`');\n",
        "axes[1].set_title('Target Imbalance on `y_dev_sampled`');\n",
        "axes[2].set_title('Target Imbalance on `y_test`');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'#Images before Upsampling:   {X_dev.shape[0]}')\n",
        "print(f'#Images after Upsampling:    {X_dev_sampled.shape[0]}')\n",
        "print(f'Upsampled Images:            {X_dev_sampled.shape[0]-X_dev.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection\n",
        "---\n",
        "\n",
        "*Feature Selection* is the process of identifying the most related features from the data and removing the irrelvant or less important features which do not contribute much to our target variable.\n",
        "\n",
        "There are a number of advantages that come along with feature selection, which make it an important step of every machine learning project.\n",
        "\n",
        "1. **Reduces Overfitting**: Less redundant data means less opportunity to make decisions based on noise.\n",
        "\n",
        "2. **Improves Accuracy**: Less misleading data means modeling accuracy improves.\n",
        "\n",
        "3. **Reduces Training Time**: fewer data points reduce algorithm complexity and algorithms train faster.\n",
        "\n",
        "Since brute-forcing the best features on a given model with 8 features already results in $\\sum_{i=1}^{8} {8 \\choose i}=255$ unique combination of features, the computational effort quickly becomes infeasible. We can therefore use statistics to try to pick the most relevant features in a computatinally less expensive way."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00065-f41ea02b-0bc5-4b45-9c2f-7b25dcb838d9",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "8c0913b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Best\n",
        "---\n",
        "\n",
        "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
        "The scikit-learn library provides the `SelectKBest` class that can be used with a suite of different statistical tests to select a specific number of features.\n",
        "\n",
        "In order to evaluate our features with respect to randomly generated data, we add some uniformly random columns to our development data, in order to select the features that are likely to perform best. \n",
        "\n",
        "It is however important to notice, that K-Best Selection is a way of selecting univariate features, meaning that it only checks the likely performance for each single feature. This method might ie. give us 5 individually good performing features, which are highly correlated. In that case, the 4 additionally selected features, don't add any value to our model and thus increase running time and potentially accuracy. "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00075-9ce8c66f-4892-46ad-b6f7-1983a4a8e83c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00068-853c950c-08b2-44b9-9c38-171085a681ec",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "45dfa306",
        "execution_millis": 1910,
        "output_cleared": false,
        "execution_start": 1619002422141,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# generate some noise\n",
        "noise_cols = 4\n",
        "features_noise = features + ['Noise' for _ in range(noise_cols)] # list of features + noise columns\n",
        "noise = np.random.RandomState(1).uniform(0,0.1, size=(noise_cols, X_dev_sampled.shape[0])).transpose()\n",
        "\n",
        "\n",
        "# feature matrix and target variable\n",
        "X_select = np.hstack((X_dev_sampled, noise))\n",
        "y_select = y_dev_sampled\n",
        "\n",
        "# plot scores for features and noise\n",
        "fig, ax = plt.subplots(ncols=5, figsize=(4*5, 3))\n",
        "fig.suptitle('Univariate Feature Scores for Features and Noise for different K-Best', fontsize=14)\n",
        "\n",
        "# select k-best\n",
        "for k in range(1,5+1):\n",
        "    kbest = SelectKBest(mutual_info_classif, k=k)\n",
        "    kbest.fit(X_select, np.ravel(y_select)) # ravel cause of sklearn warning \n",
        "    scores = kbest.scores_ # univariate features scores for each feature and noise\n",
        "\n",
        "    print('-'*10 + f' k = {k} ' + '-'*10)\n",
        "    scores_dict = {scores[i]: i for i in range(len(scores))}\n",
        "    for val in sorted(scores_dict, reverse=True)[:k]:\n",
        "        print(features_noise[scores_dict[val]])\n",
        "\n",
        "    ax[k-1].bar(np.arange(0,len(scores)), scores)\n",
        "    ax[k-1].tick_params(labelrotation=90) # readable labels\n",
        "    ax[k-1].set_xticks(np.arange(0, len(features) + noise_cols));\n",
        "    ax[k-1].set_xticklabels([f.replace('_', ' ').title() for f in features] + ['Noise' for _ in range(noise_cols)]);"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building KNN-Model\n",
        "---\n",
        "\n",
        "For the scope of this project, we first limit ourselves to a basic classifier called `KNN` (*K-Nearest-Neighbors*) algorithm, classifies out-of-sample data by evaluating the label frequency of k-surrounding (mostly measured through *euclidean distance*) neighbors in a n-dimensional space (where n is the number of features).\n",
        "\n",
        "To build the model, we choose the features selected by *K-Best Features* and and train our model using cross-validation of 5 partitions. In that way we get a more robust estimate for the performance of the metric. \n",
        "\n",
        "In this section we will build three different models:\n",
        "> **Case 1 (Baseline)**: In the baseline model, we train our model on the unbalanced dataset. We expect the model to not perform on the recall score, given the high class imbalance. \n",
        "\n",
        "> **Case 2 (Wrong Upsampling)**: Here we do the cross-validation on the entire upsampled dataset. We expect highly overconfident metrics since on each fold, we expect a number of images being a copy from an image in the training in the validation set, which results in a highly biased model that overfits the training data. This overfitting through wrong upsampling, however, is expected to be exposed when testing the model on the real test data, which achieves a similar score as the baseline.\n",
        "\n",
        "> **Case 3 (Correct Upsampling)**: Instead, we need to upsample for each training set in each of the folds in the cross-validation to create an unbiased estimation of the model’s performance. With this technique, we expect to increase the model’s performance on recall and make it robust to out-of-sample data in a way, that we perform equally good on the test data."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00072-900e0e6a-2251-4e02-9d77-771007f4cb09",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define splitting for cross-validation (shuffle=False for reproducable results) \n",
        "kf = KFold(n_splits=5,shuffle=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# selected features from k-best\n",
        "selected_features = ['compactness', 'color_variability', 'luminance_variability']\n",
        "\n",
        "# condense feature matrix to only contain selected features (in non-upsampled and upsampled development set and test set)\n",
        "X_dev_selected = X_dev[selected_features]\n",
        "X_dev_sampled_selected = X_dev_sampled[selected_features]\n",
        "\n",
        "X_test_selected = X_test[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL = {}\n",
        "MODEL['baseline'] = {}\n",
        "MODEL['upsample_before_cv'] = {}\n",
        "MODEL['upsample_during_cv'] = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialise data structure to hold performance results in the three cases\n",
        "DATA['results'] = pd.DataFrame({'Method': ['No Upsampling (Baseline)', 'Upsample Training Data before CV', 'Upsample within CV']})"
      ]
    },
    {
      "source": [
        "### Base-Performance on Unbalanced Data\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_reports = {'Classifier': [], 'Hyperparameter': [], 'Accuracy': [], 'Precision': [], 'Recall (Sensitivity)': []}\n",
        "\n",
        "params = {'n_neighbors': range(1,6), 'weights': ['distance', 'uniform']}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "grid_no_upsampling = GridSearchCV(knn, param_grid=params, cv=kf, \n",
        "                          scoring=['accuracy', 'recall'], refit='recall')\n",
        "\n",
        "grid_no_upsampling.fit(X_dev_selected, np.ravel(y_dev))\n",
        "\n",
        "# cv results\n",
        "MODEL['baseline']['cv_results'] = pd.DataFrame(grid_no_upsampling.cv_results_)\n",
        "try: os.makedirs(PATH['reports'] + 'model_evaluation/cross_val/')\n",
        "except: None\n",
        "MODEL['baseline']['cv_results'].to_csv(PATH['reports'] + 'model_evaluation/cross_val/' + 'baseline.csv')\n",
        "\n",
        "# report best score (and the hyperparameters used)\n",
        "MODEL['baseline']['best_recall'] = grid_no_upsampling.best_score_\n",
        "MODEL['baseline']['hyperparameters'] = grid_no_upsampling.best_estimator_\n",
        "\n",
        "# display results\n",
        "print(MODEL['baseline']['best_recall'])\n",
        "print(MODEL['baseline']['hyperparameters'])\n",
        "MODEL['baseline']['cv_results'] # display inline"
      ]
    },
    {
      "source": [
        "### Performance on Wrongly Upsampled Data\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_reports = {'Classifier': [], 'Hyperparameter': [], 'Accuracy': [], 'Precision': [], 'Recall (Sensitivity)': []}\n",
        "\n",
        "params = {'n_neighbors': range(1,11), 'weights': ['distance', 'uniform']}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "grid_upsampling_before_cv = GridSearchCV(knn, param_grid=params, cv=kf, \n",
        "                          scoring=['accuracy', 'recall'], refit='recall')\n",
        "\n",
        "grid_upsampling_before_cv.fit(X_dev_sampled_selected, np.ravel(y_dev_sampled))\n",
        "\n",
        "# cv results\n",
        "MODEL['upsample_before_cv']['cv_results'] = pd.DataFrame(grid_upsampling_before_cv.cv_results_)\n",
        "try: os.makedirs(PATH['reports'] + 'model_evaluation/cross_val/')\n",
        "except: None\n",
        "MODEL['upsample_before_cv']['cv_results'].to_csv(PATH['reports'] + 'model_evaluation/cross_val/' + 'upsample_before_cv.csv')\n",
        "\n",
        "# report best score (and the hyperparameters used)\n",
        "MODEL['upsample_before_cv']['best_recall'] = grid_upsampling_before_cv.best_score_\n",
        "MODEL['upsample_before_cv']['hyperparameters'] = grid_upsampling_before_cv.best_estimator_\n",
        "\n",
        "# display results\n",
        "print(MODEL['upsample_before_cv']['best_recall'])\n",
        "print(MODEL['upsample_before_cv']['hyperparameters'])\n",
        "MODEL['upsample_before_cv']['cv_results'] # display inline"
      ]
    },
    {
      "source": [
        "### Performance on Correctly Upsampled Data\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_reports = {'Classifier': [], 'Hyperparameter': [], 'Accuracy': [], 'Precision': [], 'Recall (Sensitivity)': []}\n",
        "\n",
        "params = {\n",
        "    'kneighborsclassifier__n_neighbors': range(1, 11), # technicalities\n",
        "    'kneighborsclassifier__weights': ['distance', 'uniform']\n",
        "}\n",
        "\n",
        "pipeline = make_pipeline(SMOTE(random_state=1), \n",
        "                              KNeighborsClassifier())\n",
        "grid_upsampling_during_cv = GridSearchCV(pipeline, param_grid=params, cv=kf, scoring=['accuracy', 'recall'], refit='recall')\n",
        "grid_upsampling_during_cv.fit(X_dev_selected, np.ravel(y_dev));\n",
        "\n",
        "# cv results\n",
        "MODEL['upsample_during_cv']['cv_results'] = pd.DataFrame(grid_upsampling_during_cv.cv_results_)\n",
        "try: os.makedirs(PATH['reports'] + 'model_evaluation/cross_val/')\n",
        "except: None\n",
        "MODEL['upsample_during_cv']['cv_results'].to_csv(PATH['reports'] + 'model_evaluation/cross_val/' + 'upsample_during_cv.csv')\n",
        "\n",
        "# report best score (and the hyperparameters used)\n",
        "MODEL['upsample_during_cv']['best_recall'] = grid_upsampling_during_cv.best_score_\n",
        "MODEL['upsample_during_cv']['hyperparameters'] = grid_upsampling_during_cv.best_estimator_\n",
        "\n",
        "# display results\n",
        "print(MODEL['upsample_during_cv']['best_recall'])\n",
        "print(MODEL['upsample_during_cv']['hyperparameters'])\n",
        "MODEL['upsample_during_cv']['cv_results'] # display inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA['results'] = pd.concat([DATA['results'], pd.DataFrame({'Recall Score (Validation)': [MODEL[key]['best_recall'] for key in MODEL.keys()]})], axis=1)\n",
        "DATA['results']"
      ]
    },
    {
      "source": [
        "### Evaluating Final Performance\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# fit best performing model on recall saved through grid search cv to whole dev set\n",
        "grid_no_upsampling.fit(X_dev_selected, np.ravel(y_dev)) # knn(n_neighbors=1, weights='distance')\n",
        "grid_upsampling_before_cv.fit(X_dev_sampled_selected, np.ravel(y_dev_sampled)) # KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
        "grid_upsampling_during_cv.fit(X_dev_sampled_selected, np.ravel(y_dev_sampled)) # KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "# predict test set\n",
        "pred1 = grid_no_upsampling.predict(X_test_selected)\n",
        "pred2 = grid_upsampling_before_cv.predict(X_test_selected)\n",
        "pred3 = grid_upsampling_during_cv.predict(X_test_selected)\n",
        "\n",
        "# make classification report and \n",
        "try: os.makedirs(PATH['reports'] + 'model_evaluation/test_data/')\n",
        "except: None\n",
        "pd.DataFrame(classification_report(y_test, pred1, output_dict=True)).transpose().to_csv(PATH['reports'] + 'model_evaluation/test_data/baseline.csv')\n",
        "pd.DataFrame(classification_report(y_test, pred2, output_dict=True)).transpose().to_csv(PATH['reports'] + 'model_evaluation/test_data/upsampling_before_cv.csv')\n",
        "pd.DataFrame(classification_report(y_test, pred3, output_dict=True)).transpose().to_csv(PATH['reports'] + 'model_evaluation/test_data/upsampling_during_cv.csv')\n",
        "\n",
        "# recall\n",
        "sens1 = recall_score(y_test, pred1)\n",
        "sens2 = recall_score(y_test, pred2)\n",
        "sens3 = recall_score(y_test, pred3)\n",
        "\n",
        "DATA['results'] = pd.concat([DATA['results'], pd.DataFrame({'Recall Score (Test)': [sens1, sens2, sens3]})], axis=1)\n",
        "DATA['results'].to_csv(PATH['reports'] + 'commparison_of_recall_scores.csv')\n",
        "DATA['results']"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00091-47587e16-dcca-4a6f-952c-7ead42e7a28c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7e049a0",
        "execution_millis": 29,
        "output_cleared": false,
        "execution_start": 1619003433493,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final model's performance\n",
        "print(classification_report(y_test, pred3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 3*\n",
        "# Open Question: How can we make our model more sensitive?\n",
        "\n",
        "---\n",
        "\n",
        "In the previous section we have developed a model, that is optimised for performing as well as possible on the `recall` metric on a specified classifer with specified features. However, it becomes obvious that the model is stil only able to predict roughly 40% of the *melanoma* lesions as diseased. In real-world, we would rather want to model to be more sensitive to positives, as a false negative (we do not detect cancer) has potentially fatal consequences, whereas a false positive only motivates people do go to a doctor. \n",
        "\n",
        "In this section we are therefore investigating, how we can tweak our model in a way that it gets more sensitive (increasing the 'recall' metric). In order to do so, we need a model, which outputs predictive labeling (ie. gives a probability on the binary label). With such a model, we can adjust the threshold of prediciting positive. This increases sensitivity, knowing that we will also have more false positives."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00013-facea51d-4f84-4003-a25d-67505e0f0718",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "source": [
        "## Model and Feature Selection\n",
        "---\n",
        "\n",
        "We now use the `Random Forest Classifier`, which is a widely used classifier, which allows us to adjust the performance of detecting positives through lowering the threshold for detecting them. We use the same balanced scaled development set to monitor the performance on cross-validated sets and later evaluate the final performance on the spared test-set - one time with the regular threshold of 0.5 and another time with the adjusted one."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100) # initialise random forest classifier\n",
        "\n",
        "rf.fit(X_dev_sampled, y_dev_sampled) # fit on all features and select highest scoring features\n",
        "\n",
        "rf_feature_importance = pd.DataFrame({'Feature': features, 'Importance': rf.feature_importances_})\n",
        "\n",
        "# plot\n",
        "x = sns.barplot(x='Feature', y='Importance', data=rf_feature_importance);\n",
        "x.set_title(\"Feature Importance in Random Forest Classifier\");\n",
        "x.set_xticklabels(x.get_xticklabels(), rotation=90);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select best performing features from above output\n",
        "rf_selected_features = ['compactness', 'color_variability', 'average_blue']"
      ]
    },
    {
      "source": [
        "## Train and Evaluate Models\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100) # initialise random forest classifier\n",
        "\n",
        "X_train, y_train = X_dev_sampled[rf_selected_features], np.ravel(y_dev_sampled)\n",
        "\n",
        "rf.fit(X_dev_sampled[rf_selected_features], np.ravel(y_dev_sampled))\n",
        "y_pred = rf.predict(X_test[rf_selected_features])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "labels, counts = np.unique(y_pred, return_counts=True)\n",
        "ax.bar(labels, counts, color='gray'); ax.set_xticks(labels); ax.set_xticklabels(['Non-Melanoma', 'Melanoma']); ax.set_title('Predicted Labels')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.1 # setting the threshold for positive predictions low \n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "rf.fit(X_dev_sampled[rf_selected_features], np.ravel(y_dev_sampled))\n",
        "predicted_proba = rf.predict_proba(X_test[rf_selected_features])\n",
        "y_pred = (predicted_proba [:,1] >= threshold).astype('int')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "labels, counts = np.unique(y_pred, return_counts=True)\n",
        "ax.bar(labels, counts, color='gray'); ax.set_xticks(labels); ax.set_xticklabels(['Non-Melanoma', 'Melanoma']); ax.set_title('Predicted Labels')\n",
        "\n",
        "#y_pred=clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "source": [
        "## Summary \n",
        "---\n",
        "In conclusion, one can tweak the ratio between sensitivity and specificity, but improving one will categorically impact the other negatively. Therefore, tweaking these parameters is a design choice that needs to be specifically adjusted for the classification problem at hand. It should always be the final step of perfecting a model towards desired performance."
      ],
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00025-86c4f020-f4de-43e0-88d0-d1f5b1b0874e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00026-bed7848d-d805-47f0-8bf7-523a4cb790f6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00027-65d1e65c-b9c5-4a9a-83da-9c4055f03f8c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00028-64a0d452-fc0a-40c4-a3b2-4d35e7515feb",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00029-c9887334-2738-44bb-90a3-2b94c9240649",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00030-3232008b-99b3-4ce6-8bb7-627d3c530a81",
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "7810e8fe-98e9-4f91-8d21-605a64b16e29",
    "deepnote": {},
    "deepnote_execution_queue": [],
    "kernelspec": {
      "name": "python383jvsc74a57bd0ce483ef3f3f15830cc71af6662324550274ded09d10a1a693bdaad1eb103022d",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    }
  }
}