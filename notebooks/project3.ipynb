{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 3: Skin Lesion Detection in Medical Treatment using Machine Learning\n",
        "---\n",
        "\n",
        "**Group 9: Aidan Stocks, Hugo Reinicke, Nicola Clark, Jonas-Mika Senghaas**\n",
        "\n",
        "Submission: *23.04.2021* / Last Modified: *22.04.2021*\n",
        "\n",
        "---\n",
        "\n",
        "This notebook contains the step-by-step data science process performed on the *ISIC 2017* public test data and official training data on medical image recognition. The goal of this project was to extract and automatically analyse features from medical images of skin lesions in order to predict whether or not the lesion is *melanoma* using image processing and machine learning classification algorithms.\n",
        "\n",
        "The initial data (containing the medical images, masked images and information on features and disease) was given for 150 medical images (equivalent to the public test data of the *ISIC 2017* challenge) by the project manager *Veronika *.\n",
        "To develop more accurate models, we extended the initially given data by the official training data that could be obtained from the official [ISIC 2017 Website](https://challenge.isic-archive.com/data). In a later part of the notebook, we will explain how to download the images for reproducing the results of this notebook."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00000-cb34c893-19b5-4eb7-bf5a-d02ead8d44fe",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "---\n",
        "The amount of medical imaging - just as data in any other field - has increased tremendously within the last decade, making it more and more difficult to manually inspect medical images for diagnostic purposes.\n",
        "\n",
        "Furthermore, people have proven to be hesitant of visiting doctors because of seemingly small issues, which did not seem to be important enough to occupy a doctor's time. With skin diseases being especially effective in treatment if detected early, this is fatal. \n",
        "An easy-to-use app that implements automated detection of skin diseases from the sofa, would address this issue - ultimately saving lives."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00001-0c890553-5249-4dc4-b863-ecba0193daab",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running this Notebook\n",
        "---\n",
        "This notebook contains all code to reproduce the findings of the project as can be seen on the [GitHub](https://github.com/jonas-mika/fyp2021p03g09) page of this project. \n",
        "If one downloads the images used within this project, it is important that the global paths are correctly set. This can either be achieved through locally changing the file structure (ie. naming folders as defined in the notebook) or by adjusting the global variables within the `Constants` section of this notebook.\n",
        "\n",
        "*Note that the rest of the file structure as can be seen on the [GitHub](https://github.com/jonas-mika/fyp2021p03g09) page of the project generates automatically*"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00002-9d760373-d759-41b1-9739-48d3452591b9",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Libraries \n",
        "---\n",
        "Throughout the project, we will use a range of both built-in and external Python Libraries. This notebook will only run if all libraries and modules are correctly installed on your local machines. \n",
        "To install missing packages use `pip install <package_name>` (PIP (Python Package Index) is the central package management system, read more [here](https://pypi.org/project/pip/)). You can do this directly within the notebook by uncommenting the below cell.\n",
        "\n",
        "In case you desire further information about the used packages, click the following links to find detailed documentations:\n",
        "- [Pandas](https://pandas.pydata.org/)\n",
        "- [Numpy](https://numpy.org/)\n",
        "- [Matplotlib](https://matplotlib.org/stable/index.html)\n",
        "- [PIL](https://pillow.readthedocs.io/en/stable/)\n",
        "- [SciKit Learn](https://scikit-learn.org/stable/)\n",
        "- [SciKit Image](https://scikit-image.org/)\n",
        "- [Scipy](https://www.scipy.org/)\n",
        "- [ImbLearn](https://imbalanced-learn.org/stable/)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00003-6e74ab3c-05a2-47b0-95c8-bd85fea6fefc",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-54b6965a-fb79-43bd-b513-36fb8a2673bf",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a281805d",
        "execution_millis": 5929,
        "output_cleared": true,
        "execution_start": 1618999781334,
        "deepnote_cell_type": "code"
      },
      "source": [
        "%%capture \n",
        "# stop cell from displaying output\n",
        "\n",
        "# uncomment lines with uninstalled packages on local machine\n",
        "!pip install scikit-image\n",
        "#!pip install imblearn\n",
        "#!pip install scikit-learn\n",
        "#!pip install pillow\n",
        "#!pip install itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-ce265327-d417-47b0-850b-6a4f0ab3a9cf",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3285c3db",
        "execution_millis": 3297,
        "output_cleared": true,
        "execution_start": 1618999796906,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# python standard libraries\n",
        "import os                                              # automates saving of export files (figures, summaries, ...)\n",
        "import re                                              # used for checking dateformat in data cleaning\n",
        "\n",
        "# external libraries\n",
        "import pandas as pd                                    # provides major datastructure pd.DataFrame() to store datasets\n",
        "import numpy as np                                     # used for numerical calculations and fast array manipulations\n",
        "import matplotlib.pyplot as plt                        # standard data visualisation\n",
        "import seaborn as sns                                  # convenient data visualisation\n",
        "from PIL import Image                                  # fork from PIL (python image library), image processing in python\n",
        "\n",
        "# specific functions\n",
        "import matplotlib.cm as cm\n",
        "from skimage import morphology\n",
        "#from scipy.stats.stats import mode\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.preprocessing import StandardScaler # normalise features\n",
        "from imblearn.under_sampling import RandomUnderSampler # balancing data\n",
        "from imblearn.over_sampling import RandomOverSampler # balancing data\n",
        "from imblearn.over_sampling import SMOTE # balancing data\n",
        "\n",
        "# feature selection\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest # univariate feature selection with mutual information for feature scoring\n",
        "from sklearn.feature_selection import SequentialFeatureSelector # sequential selection of k-features given fixed classifier \n",
        "\n",
        "# classifiers used in this project\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier # k-nearest neighbour classifier\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold  # producing equal cross-validation sets (reproducable results)\n",
        "from sklearn.model_selection import cross_val_score # perform cross-validation and report single metric\n",
        "from sklearn.model_selection import cross_validate # perform cross-validation and report set of metrics\n",
        "from sklearn.model_selection import GridSearchCV # perform cross-validation on given set of hyperparameters to find best hyperparamters optimising single metric\n",
        "from imblearn.pipeline import Pipeline, make_pipeline # balancing on each k-th training set in cross validation\n",
        "\n",
        "# evaluating model\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Additional Data\n",
        "---\n",
        "The data analysis was performed on the concatenated data of the 150 initially given images and 2000 additional images obtained from the same data source - the [ISIC](https://challenge.isic-archive.com/data) (International Skin Imaging Collaboration) 2017. The links automatically start the download from the website - so be aware of clicking it.\n",
        "\n",
        "> Raw Data\n",
        "\n",
        ">> [Raw Data Images](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Data.zip)\n",
        "\n",
        ">> [Raw Data Masks](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Part1_GroundTruth.zip)\n",
        "\n",
        ">> [Raw Data Ground Truth](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Part3_GroundTruth.csv)\n",
        "\n",
        "> External Data\n",
        "\n",
        ">> [External Data Images](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Data.zip)\n",
        "\n",
        ">> [External Data Masks](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part1_GroundTruth.zip)\n",
        "\n",
        ">> [External Ground Truth](https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part3_GroundTruth.csv)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00009-ab8c2759-432e-4819-be9d-80d303620266",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants\n",
        "---\n",
        "To enhance the readibilty, as well as to decrease the maintenance effort, it is useful for bigger projects to define contants that need to be accessed globally throughout the whole notebook in advance. \n",
        "The following cell contains all of those global constants. By convention, we write them in caps (https://www.python.org/dev/peps/pep-0008/#constants)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00008-8d4d4766-2724-4033-8584-15fe4722f493",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-b0a63da5-4fc5-41b4-86d4-5705799185d1",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "27b7344f",
        "execution_millis": 2,
        "output_cleared": true,
        "execution_start": 1618999811932,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# global parameters for running the notebooks (each computation )\n",
        "PREPROCESS_IMAGES = False\n",
        "COMPUTE_FEATURES = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-4e13d720-e857-4d9a-8abb-632aa8f19e3c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a1d98c23",
        "execution_millis": 7,
        "output_cleared": true,
        "execution_start": 1618999816931,
        "deepnote_cell_type": "code"
      },
      "source": [
        "PATH = {}\n",
        "PATH['data'] = {}\n",
        "PATH['data']['raw'] = \"../data/raw/\"\n",
        "PATH['data']['processed'] = \"../data/processed/\"\n",
        "PATH['data']['external'] = \"../data/external/\"\n",
        "\n",
        "PATH['images'] = 'images/'\n",
        "PATH['masks'] = 'masks/'\n",
        "PATH['filtered_images'] = 'filtered_images/'\n",
        "PATH['dummy_images']= 'dummy_images/'\n",
        "\n",
        "PATH['reports'] = \"../reports/\"\n",
        "\n",
        "# filename lookup dictionary storing the most relevant filenames\n",
        "FILENAME = {}\n",
        "\n",
        "# store filename of datasets involved\n",
        "FILENAME['diagnosis'] = 'diagnosis.csv'\n",
        "FILENAME['features'] = 'features.csv' \n",
        "\n",
        "# store filenames of different files in the project for easy iteration\n",
        "FILENAME['raw_images'] = sorted([image[:-4] for image in os.listdir(PATH['data']['raw'] + PATH['images']) if not re.match('.*super.*', image) and re.match('^ISIC', image)])\n",
        "FILENAME['raw_masks'] = sorted([mask[:-4] for mask in os.listdir(PATH['data']['raw'] + PATH['masks'])])\n",
        "FILENAME['external_images'] = sorted([image[:-4] for image in os.listdir(PATH['data']['external'] + PATH['images']) if not re.match('.*super.*', image)])[1:] # need to subscript because of weird dotfile\n",
        "FILENAME['external_masks'] = sorted([mask[:-4] for mask in os.listdir(PATH['data']['external'] + PATH['masks'])])\n",
        "\n",
        "FILENAME['all_images'] = sorted(FILENAME['raw_images'] + FILENAME['external_images'])\n",
        "FILENAME['all_masks'] = sorted(FILENAME['raw_masks'] + FILENAME['external_masks'])\n",
        "\n",
        "# defining three dictionaries to store data. each dictionary will reference several pandas dataframes\n",
        "DATA = {}\n",
        "\n",
        "NAMES = {}\n",
        "NAMES['datasets'] = ['diagnosis', 'features']\n",
        "NAMES['images'] = ['images', 'masks']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 0**\n",
        "# Image Preprocessing\n",
        "---\n",
        "In this section we preprocess our image to make it nicer to deal with them in the later part of the project.\n",
        "\n",
        "1. Crop Images and Masks to be bound by lesion\n",
        "2. Make Width and Length an even number to be able to crop evenly\n",
        "3. Maybe save filtered image with color"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00013-3916c960-be31-476a-80d7-841da336db90",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00014-13f4e761-daae-49a7-acf7-41412d5e2a0f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "23a735da",
        "execution_millis": 0,
        "output_cleared": true,
        "execution_start": 1618981586076,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# helper function to make width and lengths even\n",
        "def make_even(img):\n",
        "    if img.size[0] % 2 != 0: #  making number of cols even\n",
        "        img = np.array(img)\n",
        "        mid = int(img.shape[1] / 2)\n",
        "        img = np.delete(img, mid, axis=1)\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    if img.size[1] % 2 != 0: # making number of rows even\n",
        "        img = np.array(img)\n",
        "        mid = int(img.shape[0] / 2)\n",
        "        img = np.delete(img, mid, axis=0)\n",
        "        img = Image.fromarray(img)\n",
        "    \n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00014-e8cc52ac-d501-404c-b8ab-f75edf0227d4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ad6ddc9e",
        "execution_millis": 0,
        "output_cleared": true,
        "execution_start": 1618981586453,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# preprocessing (170 seconds to run)\n",
        "if PREPROCESS_IMAGES == True:\n",
        "    try: \n",
        "        os.makedirs(PATH['data']['processed'] + PATH['images'])\n",
        "        os.makedirs(PATH['data']['processed'] + PATH['masks'])\n",
        "        os.makedirs(PATH['data']['processed'] + PATH['filtered_images'])\n",
        "    except: print('Directories already exist.')\n",
        "\n",
        "    print('Starting Preprocessing of Raw Images...')\n",
        "    for i in range(150):\n",
        "        # get image names\n",
        "        img_name = FILENAME['raw_images'][i] + '.jpg'\n",
        "        mask_name = FILENAME['raw_masks'][i] + '.png'\n",
        "\n",
        "        # open temporarily\n",
        "        img = Image.open(PATH['data']['raw'] + PATH['images'] + img_name)\n",
        "        mask = Image.open(PATH['data']['raw'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        # crop to only store lesion\n",
        "        cropped_img = img.crop(mask.getbbox())\n",
        "        cropped_mask = mask.crop(mask.getbbox())\n",
        "\n",
        "        # make width and length even (two cases)\n",
        "        cropped_img = make_even(cropped_img)\n",
        "        cropped_mask = make_even(cropped_mask)\n",
        "\n",
        "        # create filtered with color\n",
        "        dummy = Image.new(\"RGB\", cropped_img.size, 0)\n",
        "        filtered_img = Image.composite(cropped_img, dummy, cropped_mask)\n",
        "        \n",
        "        # save to '../data/processed' in correct subfolder\n",
        "        cropped_img.save(PATH['data']['processed'] + PATH['images'] + img_name)\n",
        "        cropped_mask.save(PATH['data']['processed'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        filtered_img.save(PATH['data']['processed'] + PATH['filtered_images'] + img_name)\n",
        "\n",
        "    print('Processed Raw-Data\\n')\n",
        "    print('Starting Preprocessing of External Images...')\n",
        "\n",
        "    for i in range(2000):\n",
        "        # get image names\n",
        "        img_name = FILENAME['external_images'][i] + '.jpg'\n",
        "        mask_name = FILENAME['external_masks'][i] + '.png'\n",
        "\n",
        "        # open temporarily\n",
        "        img = Image.open(PATH['data']['external'] + PATH['images'] + img_name)\n",
        "        mask = Image.open(PATH['data']['external'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        # crop to only store lesion\n",
        "        cropped_img = img.crop(mask.getbbox())\n",
        "        cropped_mask = mask.crop(mask.getbbox())\n",
        "\n",
        "        # make width and length even (two cases)\n",
        "        cropped_img = make_even(cropped_img)\n",
        "        cropped_mask = make_even(cropped_mask)\n",
        "\n",
        "        # create filtered with color\n",
        "        dummy = Image.new(\"RGB\", cropped_img.size, 0)\n",
        "        filtered_img = Image.composite(cropped_img, dummy, cropped_mask)\n",
        "        \n",
        "        # save to '../data/processed' in correct subfolder\n",
        "        cropped_img.save(PATH['data']['processed'] + PATH['images'] + img_name)\n",
        "        cropped_mask.save(PATH['data']['processed'] + PATH['masks'] + mask_name)\n",
        "        filtered_img.save(PATH['data']['processed'] + PATH['filtered_images'] + img_name)\n",
        "        \n",
        "        \n",
        "    print('Preprocessing Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 0.5*\n",
        "# Data Exploration\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00010-94b50f7c-6711-4349-bbfc-c11ba8d47de0",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in Data\n",
        "\n",
        "---\n",
        "\n",
        "The task involves different sources of data, namely:\n",
        "\n",
        "> **Images**: 150 Medical Images of Skin Lesions\n",
        "\n",
        "> **Masks**: 150 Binary Masks corresponding to each Image that masks the region of the Skin Lesion\n",
        "\n",
        "> **Diagnosis**: Dataset storing whether or not the lesion was either *melanoma* or *seborrheic_keratosis* through binary values\n",
        "\n",
        "> **Features**: Dataset storing the area and perimeter of the skin lesion for each image\n",
        "\n",
        "We conveniently load in the csv datasets into individual `Pandas DataFrames` using the built-in pandas method `pd.read_csv()`. We store those in our `DATA` dictionary in the corresponding keys.\n",
        "\n",
        "All images and masks are stored as `Image` objects of the `PIL` (*Python Image Library*) for convenient handling of image processing functionality."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00011-b337fa92-d698-471c-bc5b-f941c1aef692",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "b623e53d",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-2900529b-7a4b-4fce-bc3c-11beff12d811",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e604c12e",
        "execution_millis": 15,
        "output_cleared": true,
        "execution_start": 1618999822838,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# load in raw datasets \n",
        "DATA['raw_diagnosis'] = pd.read_csv(PATH['data']['raw'] + FILENAME['diagnosis']) # 150 x 3\n",
        "DATA['external_diagnosis'] = pd.read_csv(PATH['data']['external'] + FILENAME['diagnosis']) # 2000 x 3\n",
        "\n",
        "# concatenate into big dataframe\n",
        "DATA['diagnosis'] = pd.concat([DATA['raw_diagnosis'], DATA['external_diagnosis']], ignore_index=True).sort_values(by=['image_id']) # 2150 x 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspection of Dataset (Target Variable)\n",
        "\n",
        "---\n",
        "\n",
        "We can now have a look at our two datasets to get a first impression for what kind of data we are dealing with. We start by reporting the number of records and fields/ variables in each of the datasets by using the shape property of the `pd.DataFrame`. We then continue to have an actual look into the data. Similiar to the head command in terminal, we can use the method `head()` onto our DataFrames, which outputs an inline representation of the first five data records of the dataset."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00015-bc508507-98dd-4277-95d2-820a3765f909",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00016-d2dacc61-945c-4362-8d5d-474ff69ead14",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00015-061506db-72d9-42ea-8d71-96b100252925",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "cf497bf3",
        "execution_millis": 14,
        "output_cleared": false,
        "execution_start": 1618999831092,
        "deepnote_cell_type": "code"
      },
      "source": [
        "print(f\"Diagnosis: {DATA['diagnosis'].shape}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diagnosis Dataset**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00019-32045793-8a8c-4aae-a08f-8a8d0c8482e6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00020-46b4d62f-7504-43ed-9415-48567333d4fb",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "8e901a74",
        "execution_millis": 40,
        "output_cleared": false,
        "execution_start": 1618999831911,
        "deepnote_cell_type": "code"
      },
      "source": [
        "DATA['diagnosis'].head() # confirm its sorted"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00025-19369e86-c8a2-44c4-982f-5ce5a8148e3f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "881eae63",
        "execution_millis": 172,
        "output_cleared": true,
        "execution_start": 1618999832564,
        "deepnote_cell_type": "code"
      },
      "source": [
        "%%capture\n",
        "# extract cols\n",
        "mel = DATA['diagnosis']['melanoma']\n",
        "ker = DATA['diagnosis']['seborrheic_keratosis']\n",
        "\n",
        "# mask all cases\n",
        "mel_mask = (mel == 1) & (ker == 0)\n",
        "ker_mask = (mel == 0) & (ker == 1)\n",
        "neither_mask = (mel == 0) & (ker == 0)\n",
        "both_mask = (mel == 1) & (ker == 1)\n",
        "\n",
        "# append 3-class label into 'diagnosis' col\n",
        "DATA['diagnosis']['diagnosis'] = 0\n",
        "for i in range(DATA['diagnosis'].shape[0]):\n",
        "    if mel_mask[i]: DATA['diagnosis']['diagnosis'].loc[i] = 2\n",
        "    elif ker_mask[i]: DATA['diagnosis']['diagnosis'].loc[i] = 1\n",
        "    else: DATA['diagnosis']['diagnosis'].loc[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00022-0c9e3f29-3e98-440d-99b0-d600fc63f164",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a3ce5907",
        "execution_millis": 301,
        "output_cleared": false,
        "execution_start": 1618999834930,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# distribution of diagnosis\n",
        "diagnosis, counts = np.unique(DATA['diagnosis']['diagnosis'], return_counts=True)\n",
        "\n",
        "for x in range(len(diagnosis)):\n",
        "    print(f\"{diagnosis[x]}: {counts[x]}\")\n",
        "\n",
        "# plot\n",
        "fig,ax = plt.subplots()\n",
        "ax.bar(diagnosis, counts, color='gray')\n",
        "# maybe add text with numeric count\n",
        "ax.set_title('Distribution of Diagnosis', fontweight='bold'); ax.set_xlabel('Diagnosis', fontstyle='italic'); ax.set_ylabel('Frequency', fontstyle='italic');\n",
        "ax.set_xticks(diagnosis); ax.set_xticklabels(['Neither', 'Keratosis', 'Melanoma']);"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the majority of observed skin lesions was healthy (78 / 150), one fifth of the skin lesions were diagnosed with melanoma and approximately one fourth was diagnosed with keratosis. \n",
        "\n",
        "The two diseases are - as expected - mutually exclusive, meaning that a single skin lesion cannot be diagnosed with multiple diseases."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00026-e5b563ed-0d60-4d37-ac09-3cc0a1505f27",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspection of Images\n",
        "---\n",
        "The main part of the project is to analyse medical images for a set of features. To do so, we can analyse both the original image and a binary mask provided in the raw data. In this section, we will look at examples of images and their corresponding mask to get a feel for the type of images we are dealing with and assess the quality of the masks."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00022-74d262e9-0785-418b-a633-7e5351b05a1e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00023-98a3e227-2bf8-417a-80a6-b3badc4edf43",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "759b8a1",
        "execution_millis": 2586,
        "output_cleared": false,
        "execution_start": 1618999853711,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# load test image using PIL\n",
        "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(15,15))\n",
        "fig.suptitle('Examples of Images and Corresponding Masks', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i in range(3):\n",
        "    ex_img = Image.open('../data/processed/images/' + FILENAME['all_images'][i] + '.jpg')\n",
        "    ex_img_mask = Image.open('../data/processed/masks/' + FILENAME['all_masks'][i] + '.png')\n",
        "\n",
        "    ax[i][0].imshow(ex_img)\n",
        "    ax[i][0].set_xlabel(f\"{ex_img.format}, {ex_img.size}, {ex_img.mode}\");\n",
        "    ax[i][1].imshow(ex_img_mask, cmap='gray')\n",
        "    ax[i][1].set_xlabel(f\"{ex_img_mask.format}, {ex_img_mask.size}, {ex_img_mask.mode}\");\n",
        "\n",
        "ax[0][0].set_title('Medical Image');\n",
        "ax[0][1].set_title('Corresponding Binary Mask');\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 1*\n",
        "# Extracting Features \n",
        "\n",
        "---\n",
        "\n",
        "We need to find quantitative measures of how to best classify the skin abnormalities. The following handcrafted features are assessed during this project:\n",
        "\n",
        "> **Compactness**. A quantitative measure of the shape of the lesion. The smaller the value, the more compact the lesion is. A perfect circle has a compactness score of roughly *1.4*.\n",
        "\n",
        "> **Average Luminance**. A quantitative measure of the averaged brightness of the lesion. The higher the value, the lighter the lesion, and vice versa. Values range from 0 (meaning 100% black) to 255 (meaning 100% white).\n",
        "\n",
        "> **Luminance Variability**. A quantitative measure to determine the variation of luminance of the lesion. The higher the value, the more variation can be found on the lesion. \n",
        "\n",
        "> **Average Colour**. A quantitative measure of the averaged colour of the lesion. Values are in RGB format\n",
        "\n",
        "> **Colour Variability**. A quantitative measure to determine the variation of color of the lesion. The higher the value, the more variation can be found on the lesion. output in the format of (rvariation,gvariation,bvariation),average variation\n",
        "\n",
        "> **Asymmetry**. A quantitative measure to assess the symmetry of the lesion. Measured through relative number of non-overlapping pixels in different rotations. The higher the value, the less symmmetric the lesion is. A perfect circle, should score a 0 asymmetry score."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00011-2f24366e-2e6e-4fb6-bd80-8420bbf40dde",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for Feature Extraction"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00032-577c1d3c-aca3-4b53-b527-01781d1e819a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00033-50ce0ba4-6e2a-4f83-9209-da3d252a2ab3",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ef3eec4d",
        "execution_millis": 0,
        "output_cleared": true,
        "execution_start": 1618999888016,
        "deepnote_cell_type": "code"
      },
      "source": [
        "def measure_area_perimeter(mask):\n",
        "    # Measure area: the sum of all white pixels in the mask image\n",
        "    mask = np.where(np.array(mask)==255, 1, 0)\n",
        "    \n",
        "    # compute area as number of white pixels \n",
        "    area = np.sum(mask)\n",
        "\n",
        "    # compute perimeter by eroding 1 pixel from mask and then compute the difference between original and eroded mask\n",
        "    struct_el = morphology.disk(1)\n",
        "    mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
        "    image_perimeter = mask - mask_eroded\n",
        "    perimeter = np.sum(image_perimeter)\n",
        "    \n",
        "    return area, perimeter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00029-d9616ba2-826f-40c2-8d07-5d8ab8fd7c5e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b436d025",
        "execution_millis": 5,
        "output_cleared": true,
        "execution_start": 1618999888783,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# compactness\n",
        "def get_compactness(mask):\n",
        "    area, perimeter = measure_area_perimeter(mask)\n",
        "\n",
        "    # return compactness formula\n",
        "    return ( ( perimeter ** 2) / (4 * np.pi * area ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00028-ef906370-e43a-41aa-90d7-aa44d8cf16fe",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ba4da5b5",
        "execution_millis": 6,
        "output_cleared": true,
        "execution_start": 1618999889269,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# average luminance\n",
        "def get_average_luminance(filtered_image): # image needs to be filtered for lesion\n",
        "    gray = np.array(filtered_image.convert('L')) # converting to gray scale \n",
        "    return round(np.mean(gray[gray > 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00042-54d6c44d-ae8c-4362-ad59-6e7e30c06b71",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e39f82f",
        "execution_millis": 12,
        "output_cleared": true,
        "execution_start": 1618999889756,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# luminance variability\n",
        "def get_luminance_variability(filtered_image, measure='variance'):\n",
        "    gray = np.array(filtered_image.convert('L')) # converting to gray scale \n",
        "    if measure == 'variance': return round(np.var(gray[gray > 0]))\n",
        "    elif measure == 'standard_deviation': return round(np.std(gray[gray > 0]))\n",
        "    else: print('Cannot compute this `measure`. Try `variance` or `standard_deviation`')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00056-68ee87e3-71b4-493a-b296-a58f9365fcda",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a9eb3fdc",
        "execution_millis": 5,
        "output_cleared": true,
        "execution_start": 1618999893143,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# average color\n",
        "def get_average_color(filtered_image): # image needs to be filtered for lesion\n",
        "    r, g, b = filtered_image.split() # converting to separate channels  \n",
        "    r= np.array(r) \n",
        "    g= np.array(g)\n",
        "    b= np.array(b) \n",
        "    return [round(np.mean(r[r > 0])),round(np.mean(g[g > 0])),round(np.mean(b[b > 0]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00043-e14402fc-ca64-4234-8d4d-9c6a06ddfcb8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d728f987",
        "execution_millis": 21,
        "output_cleared": true,
        "execution_start": 1618999894117,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# color variability\n",
        "def get_color_variability(filtered_image, measure='variance'): # image needs to be filteredd for lesion\n",
        "    r, g, b = filtered_image.split() # converting to separate channels  \n",
        "    r= np.array(r) \n",
        "    g= np.array(g)\n",
        "    b= np.array(b) \n",
        "    if measure == 'variance': rgb=(np.var(r[r > 0]),np.var(g[g > 0]),np.var(b[b > 0]))\n",
        "    elif measure == 'standard_deviation': rgb=(np.std(r[r > 0]),np.std(g[g > 0]),np.std(b[b > 0]))\n",
        "    else: return \n",
        "    return np.mean(rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00038-30509f12-2361-4e03-804c-cdc34f4aea6f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1dbe74ba",
        "execution_millis": 7,
        "output_cleared": true,
        "execution_start": 1618999900075,
        "deepnote_cell_type": "code"
      },
      "source": [
        "def get_asymmetry(mask):\n",
        "    return round(np.mean([asymmetry(mask), asymmetry(mask.rotate(90, expand=True))]),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00030-7ee66c85-2792-4ad4-935f-dfc3e8257a30",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ce804e57",
        "execution_millis": 4,
        "output_cleared": true,
        "execution_start": 1618999900459,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# helper for asymmetry\n",
        "def asymmetry(mask):\n",
        "    # calculate basic properties of image\n",
        "    width, length = mask.size  # requires even number of pixels in both dimensions\n",
        "    size = width * length\n",
        "\n",
        "    if width%2!=0:\n",
        "        print(\"Uneven Number of Pixels. Can't calculate asymmetry.\")\n",
        "\n",
        "    # cut in half and fold\n",
        "    left = mask.crop((0,0,(width/2), length)) \n",
        "    right = mask.crop((width/2,0,width,length))\n",
        "    right = right.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "    # get binary array of unequal positions (the closer the sum to 0, the better the symmetry)\n",
        "    diff = np.where(np.array(left) != np.array(right), 1, 0)\n",
        "\n",
        "    return np.sum(diff) / (size / 2) # percentage of asymmetric pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Feature Extraction\n",
        "---\n",
        "\n",
        "Here we test the quality of the functions on sample lesions and dummy images."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00055-1858f146-2046-4965-b2cc-f966cab2caf6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00042-1eae9862-d608-44ec-b89e-54ecf331b7b9",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "31dd0608",
        "execution_millis": 2379,
        "output_cleared": false,
        "execution_start": 1618999904924,
        "deepnote_cell_type": "code"
      },
      "source": [
        "dummies = ['dummy' + str(i+1) for i in range(2)]\n",
        "\n",
        "# show dummy image and mask\n",
        "fig, ax = plt.subplots(nrows=len(dummies), ncols=2, figsize=(16, 6 * len(dummies)))\n",
        "fig.suptitle(\"Feature Extration on Dummies\", fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, img_name in enumerate(dummies):\n",
        "    # compute features\n",
        "    img = Image.open('../data/external/dummy_images/' + img_name + '.jpg')\n",
        "    img_mask = Image.open('../data/external/dummy_images/' + img_name + '_mask.png').convert('L')\n",
        "\n",
        "    area, perimeter = measure_area_perimeter(img_mask)\n",
        "    compactness = get_compactness(img_mask)\n",
        "    asymmetry_score = get_asymmetry(img_mask)\n",
        "    average_luminance = get_average_luminance(img)\n",
        "    luminance_variance = get_luminance_variability(img)\n",
        "    average_colors = get_average_color(img)\n",
        "    color_variance = get_color_variability(img)\n",
        "\n",
        "    # print out computed features\n",
        "    print('#'*15 + f\"   Dummy {i+1}   \" + '#'*15)\n",
        "    print(f\"Area / Perimeter      : {area}px / {perimeter}px\")\n",
        "    print(f\"Compactness           : {compactness}\")\n",
        "    print(f\"Asymmetry             : {asymmetry_score}px\")\n",
        "    print(f\"Average Luminance     : {average_luminance}\")\n",
        "    print(f\"Luminance Variance    : {luminance_variance}\")\n",
        "    print(f\"Average Colors (RGB)  : {average_colors}\")\n",
        "    print(f\"Color Variability     : {color_variance}\\n\")\n",
        "\n",
        "    ax[i][0].imshow(img);\n",
        "    ax[i][1].imshow(img_mask, cmap='gray');\n",
        "    ax[i][0].set_title(f'Dummy {i+1}', fontsize=10, fontstyle='italic')\n",
        "    ax[i][1].set_title(f'Dummy {i+1} Mask', fontsize=10, fontstyle='italic')\n",
        "    ax[i][0].set_xlabel(f'{img.format}, {img.size}, {img.mode}', fontstyle='italic');\n",
        "    ax[i][1].set_xlabel(f'{img_mask.format}, {img_mask.size}, {img_mask.mode}', fontstyle='italic');"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Features\n",
        "---\n",
        "\n",
        "We have developed our functions to extract abstracted features from the medical images of the lesions and have proven them to work on dummy images, where we were able to validate assumed scores in each feature. We can therefore now compute the features for each image and append it to our main dataframe to store the data, that is later used to train our model. \n",
        "\n",
        "We first read in the measured features into a dictionary `feature_dict`, which we later concatenate horizontally with `features.csv` dataset. "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00053-e69f91a1-e003-4880-bc8e-9ccdc2a51e04",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00059-ff38722b-dbe7-43fd-85ea-453cf62b1180",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2d7e6f16",
        "execution_millis": 1,
        "output_cleared": true,
        "execution_start": 1619000224638,
        "deepnote_cell_type": "code"
      },
      "source": [
        "features = ['compactness', 'average_luminance', 'luminance_variability', 'average_red', 'average_green', 'average_blue', 'color_variability', 'asymmetry']\n",
        "\n",
        "feature_functions = {\n",
        "    'compactness': get_compactness,\n",
        "    'average_luminance': get_average_luminance,\n",
        "    'luminance_variability': get_luminance_variability,\n",
        "    'average_red': get_average_color,\n",
        "    'average_green': get_average_color,\n",
        "    'average_blue': get_average_color,\n",
        "    'color_variability': get_color_variability,\n",
        "    'asymmetry': get_asymmetry\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COMPUTE_FEATURES=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00054-4dafbcbe-8adc-43ff-942e-82502bfbf355",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ff8e3abd",
        "execution_millis": 107882,
        "output_cleared": true,
        "execution_start": 1619000225591,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# compute all features (execution time: >8min)\n",
        "if COMPUTE_FEATURES == True:\n",
        "    feature_dict = {feature: [] for feature in features}\n",
        "\n",
        "    for i in range(len(FILENAME['all_images'])):\n",
        "        name = FILENAME['all_images'][i]\n",
        "        img_name = FILENAME['all_images'][i] + '.jpg'\n",
        "        mask_name = FILENAME['all_masks'][i] + '.png'\n",
        "\n",
        "        # open temporarily\n",
        "        filtered_img = Image.open(PATH['data']['processed'] + PATH['filtered_images'] + img_name)\n",
        "        mask = Image.open(PATH['data']['processed'] + PATH['masks'] + mask_name)\n",
        "\n",
        "        # measure features and append to feature_dict\n",
        "        for feature in features:\n",
        "            if feature in ['compactness', 'asymmetry']:\n",
        "                feature_dict[feature].append(feature_functions[feature](mask))\n",
        "            elif feature in ['average_luminance', 'luminance_variability', 'color_variability']:\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img))\n",
        "            elif feature == 'average_red':\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img)[0])\n",
        "            elif feature == 'average_green':\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img)[1])\n",
        "            elif feature == 'average_blue':\n",
        "                feature_dict[feature].append(feature_functions[feature](filtered_img)[2])\n",
        "        \n",
        "    # append extracted features and diagnosis to features.csv\n",
        "    DATA['features'] = pd.DataFrame({'id': FILENAME['all_images']})\n",
        "    DATA['features'] = pd.concat([DATA['features'], pd.DataFrame(feature_dict), DATA['diagnosis'][['melanoma', 'seborrheic_keratosis', 'diagnosis']]], axis=1) # concatenating handcrafted features and diagnosis\n",
        "\n",
        "    # save all computed features\n",
        "    DATA['features'].to_csv(PATH['data']['processed'] + 'features.csv')\n",
        "\n",
        "else: DATA['features'] = pd.read_csv(PATH['data']['processed'] + 'features.csv').iloc[: , 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Main DataFrame\n",
        "---\n",
        "*add small description*"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00054-91ebedfb-45da-4415-a8a8-795538fbefa6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00060-344598b0-1f7c-4353-997d-46f4c12178aa",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4c274380",
        "execution_millis": 110,
        "output_cleared": false,
        "execution_start": 1619000764532,
        "deepnote_cell_type": "code"
      },
      "source": [
        "DATA['features']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 1.5*\n",
        "# Evaluate Features for Classification\n",
        "---\n",
        "\n",
        "In this section, we are plotting the handcrafted features in order to see, whether any correaltions appear. Since we are trying to classify a binary label, namely whether a lesion is diseased with *melanoma* or not, we plot the distribution of each feature in the two classes *melanoma* and *no melanoma* to get a visual intuition of how good the specific feature might be able to distinguish between our target label. \n",
        "The more distinct the two distributions are, the better the feature will be at prediciting the tartget value."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00053-69c9fc88-3be3-4112-8c01-f0dbb64ad41a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visual Exploration"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00062-7e6b9ce6-6d64-4bad-9689-2e22cb93bfbf",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00056-59589987-30e3-42b4-b59a-04f452c8a344",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "bb95ba7a",
        "execution_millis": 1807,
        "output_cleared": true,
        "execution_start": 1618981735158,
        "deepnote_cell_type": "code"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=len(features), figsize=(8, 6 * len(features)))\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    sns.violinplot(x='melanoma', \n",
        "                   y=feature, \n",
        "                   data=DATA['features'],  \n",
        "                   ax=ax[i]).set_title(f\"Distribution of {feature.title().replace('_', ' ')} in Different Classes\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00067-14466d2a-d096-4e81-a4d6-25b9d15b5e50",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "6af9874d",
        "execution_millis": 47781,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": [
        "sns.pairplot(DATA['features'], hue='melanoma', height=2, diag_kind=\"hist\"); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 2*\n",
        "# Predict Diagnosis\n",
        "\n",
        "---\n",
        "\n",
        "We have 'handcrafted' a number of features and now aim to find the model that is the most robust to predict our target variable - whether the lesion is our is not diseased with melanoma. In the process of doing so, a number of questions arise that we will step-by-step tackle in order to build the 'best' model. \n",
        "\n",
        "\n",
        "\n",
        "> **Selecting Features**: Which combination of features is likely do perform best?\n",
        "\n",
        "> **Normalisation**: How do we make sure that each feature contributes equally to the model's prediction?\n",
        "\n",
        "> **Which model does best in predicting our variable?**\n",
        "\n",
        "> **Which hyperparameters should we use to create the best model?**\n",
        "\n",
        "> **How do we evaluate the model? Which metrics do we use to assess whether or not our model does good?**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00012-7fd9c2d5-6342-493a-af45-dc85efb4d664",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Initial Features and Target Variable\n",
        "---\n",
        "First, we need to define from which set of features our model should choose the ones that are likely to perform best on a specified target variable. \n",
        "In our case, each measured feature is potentially interesting for the model, and we want to predict the binary label, whether or not the classifier is diseased with *melanoma* or not.\n",
        "\n",
        "By, convention, we call the feature matrix `X` and the target column `y`."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00067-01107798-cc24-4632-a815-3423c563b1f0",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = DATA['features'][features]\n",
        "y = DATA['features'][['melanoma']]"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00068-a4ea27ed-35f8-42a1-8ce0-beed82d2528b",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1274c265",
        "execution_millis": 5,
        "output_cleared": true,
        "execution_start": 1619001396722,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split\n",
        "---\n",
        "Before, we doing anything further with our data, we split our data into a `development` set and a `test` set. The test set will be used to assess the final performance of the model by mimicing a true *out-of-sample* set of datapoints. For this project, we chose a standard split size of `0.3`, meaning that 30% of the original data will be used for testing, and 70% for the development of the model.\n",
        "\n",
        "We split the data at this early stage to not bias our model towards the test dataset, ie. performing the feature selection process on all of the data, might bias it towards the test data, and thus result in a sligthly overfitted model, that might perform good on the test, but not in real-life. \n",
        "\n",
        "*Note: Whenever there is randomness involved, we set `random_state=1` to produce reproducable results.*"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00065-dc7dbdd2-dbd1-4a7d-a7e8-9f93e056de62",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into dev-test data (hold-out data to mimic true 'out-of-sample' data)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00066-81016beb-b954-4925-a39e-26939fbbc303",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "511c379a",
        "execution_millis": 1,
        "output_cleared": true,
        "execution_start": 1619001927120,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_dev.shape, y_dev.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalisation\n",
        "---\n",
        "Our measured handcrafted features all perform on different scales, ie. the *average luminance* can only obtain values between 0 and 255, whereas the *asymmetry* is the number of non-matching pixels in two-folds.\n",
        "\n",
        "Since we want each of our features to equally contribute to the prediction of the model, we need to normalise them. We do this through the formula of the standard score $\\frac{x-\\mu}{\\sigma}$ ([Wikipedia](https://en.wikipedia.org/wiki/Standard_score)).\n",
        "\n",
        "We can easily use `sklearn`'s `StandardScaler`, which does the job for us."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00077-b097ada6-58a9-40c9-90ca-d8dcbad7434a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of features after normalisation\n",
        "plt.figure(figsize=(15,5));\n",
        "sns.boxplot(data=X_dev, width=0.5);"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00072-d68daeff-2cd4-4673-8d0f-997340d766de",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "5fba9c86",
        "execution_millis": 536,
        "output_cleared": false,
        "execution_start": 1619001428586,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(X_dev) # (x - mu) / std\n",
        "X_dev = pd.DataFrame(scaler.transform(X_dev), columns=features)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=features)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00078-c08a7e1c-a0ee-4d29-9ea6-3ee1b70ea292",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "41bfd634",
        "execution_millis": 12,
        "output_cleared": true,
        "execution_start": 1619001427490,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of features before normalisation\n",
        "plt.figure(figsize=(15,5));\n",
        "sns.boxplot(data=X_dev, width=0.5);"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00070-1542bccc-2f57-49fb-b39d-f1844e915367",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6444a681",
        "execution_millis": 519,
        "output_cleared": false,
        "execution_start": 1619001398505,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "### Balancing Data\n",
        "---\n",
        "As we have seen in the initial exploration of the data, the labels are heavily imbalanced. Out of the 150 observed images, only 30 are diseased with *melanoma*, which results in precisely 20% of the data. If we would naively train our model disregarding the imbalance and only evaluate the model's performance by its *accuracy score*, we are likely to see a model performing equally or very similar to the so-called *null-hypotheses* (always predicting the dominating label), which would lead to a 80% accuracy in our case. \n",
        "\n",
        "To prevent this we balance our data, such that at the end of the process the data we train our model has equal amounts of *melanoma* and *not melanoma*.\n",
        "There are two ways of doing this:\n",
        "\n",
        "> **Random Undersampling**: Cutting down the frequency of the dominant label.\n",
        "\n",
        "> **Random Oversampling**: Duplicating the less dominant feature.\n",
        "\n",
        "Although, both option are obviously not ideal (since we loose information in the first, and create duplicate information in the second), and we would always prefer a orginally balanced dataset, we need to make a choice. For this project, we *upsampled* our data, since undersampling, would have limited our whole analyis to only 60 images, which is likely to not create an accurate model.\n",
        "\n",
        "We oversample using `imblearn`'s class `RandomOverSampler`."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot before oversampling\n",
        "fig, axes = plt.subplots(ncols=3, figsize=(12, 3))\n",
        "for ax, dataset in zip(axes, [y, y_dev, y_test]):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    ax.bar(unique, counts); ax.set_xticks([1,0])\n",
        "axes[0].set_title('Target Imbalance on `y`');\n",
        "axes[1].set_title('Target Imbalance on `y_dev`');\n",
        "axes[2].set_title('Target Imbalance on `y_test`');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# balance data (using over-sampling)\n",
        "oversampler = RandomOverSampler(random_state=1)\n",
        "X_dev_sampled, y_dev_sampled = oversampler.fit_resample(X_dev, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot after oversampling\n",
        "fig, axes = plt.subplots(ncols=3, figsize=(12, 3))\n",
        "for ax, dataset in zip(axes, [y, y_dev_sampled, y_test]):\n",
        "    unique, counts = np.unique(dataset, return_counts=True)\n",
        "    ax.bar(unique, counts); ax.set_xticks([1,0])\n",
        "axes[0].set_title('Target Imbalance on `y`');\n",
        "axes[1].set_title('Target Imbalance on `y_dev_sampled`');\n",
        "axes[2].set_title('Target Imbalance on `y_test`');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'#Images before Upsampling:   {X_dev.shape[0]}')\n",
        "print(f'#Images after Upsampling:    {X_dev_sampled.shape[0]}')\n",
        "print(f'Upsampled Images:            {X_dev_sampled.shape[0]-X_dev.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection\n",
        "---\n",
        "\n",
        "*Feature Selection* is the process of identifying the most related features from the data and removing the irrelvant or less important features which do not contribute much to our target variable.\n",
        "\n",
        "There are a number of advantages that come along with feature selection, which make it an important step of every machine learning project.\n",
        "\n",
        "1. **Reduces Overfitting**: Less redundant data means less opportunity to make decisions based on noise.\n",
        "\n",
        "2. **Improves Accuracy**: Less misleading data means modeling accuracy improves.\n",
        "\n",
        "3. **Reduces Training Time**: fewer data points reduce algorithm complexity and algorithms train faster.\n",
        "\n",
        "(1 choose 8) * (2 choose 8) * (3 choose 8) * ... * (8 choose 8)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00065-f41ea02b-0bc5-4b45-9c2f-7b25dcb838d9",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "8c0913b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Best\n",
        "---\n",
        "\n",
        "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
        "The scikit-learn library provides the `SelectKBest` class that can be used with a suite of different statistical tests to select a specific number of features.\n",
        "\n",
        "In order to evaluate our features with respect to randomly generated data, we add some uniformly random columns to our development data, in order to select the features that are likely to perform best. \n",
        "\n",
        "It is however important to notice, that K-Best Selection is a way of selecting univariate features, meaning that it only checks the likely performance for each single feature. This method might ie. give us 5 individually good performing features, which are highly correlated. In that case, the 4 additionally selected features, don't add any value to our model and thus increase running time and potentially accuracy. "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00075-9ce8c66f-4892-46ad-b6f7-1983a4a8e83c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00068-853c950c-08b2-44b9-9c38-171085a681ec",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "45dfa306",
        "execution_millis": 1910,
        "output_cleared": false,
        "execution_start": 1619002422141,
        "deepnote_cell_type": "code"
      },
      "source": [
        "# generate some noise\n",
        "noise_cols = 4\n",
        "features_noise = features + ['Noise' for _ in range(noise_cols)] # list of features + noise columns\n",
        "noise = np.random.RandomState(1).uniform(0,0.1, size=(noise_cols, X_dev_sampled.shape[0])).transpose()\n",
        "\n",
        "\n",
        "# feature matrix and target variable\n",
        "X_select = np.hstack((X_dev_sampled, noise))\n",
        "y_select = y_dev_sampled\n",
        "\n",
        "# plot scores for features and noise\n",
        "fig, ax = plt.subplots(ncols=5, figsize=(4*5, 3))\n",
        "fig.suptitle('Univariate Feature Scores for Features and Noise for different K-Best', fontsize=14)\n",
        "\n",
        "# select k-best\n",
        "for k in range(1,5+1):\n",
        "    kbest = SelectKBest(mutual_info_classif, k=k)\n",
        "    kbest.fit(X_select, np.ravel(y_select)) # ravel cause of sklearn warning \n",
        "    scores = kbest.scores_ # univariate features scores for each feature and noise\n",
        "\n",
        "    print('-'*10 + f' k = {k} ' + '-'*10)\n",
        "    scores_dict = {scores[i]: i for i in range(len(scores))}\n",
        "    for val in sorted(scores_dict, reverse=True)[:k]:\n",
        "        print(features_noise[scores_dict[val]])\n",
        "\n",
        "    ax[k-1].bar(np.arange(0,len(scores)), scores)\n",
        "    ax[k-1].tick_params(labelrotation=90) # readable labels\n",
        "    ax[k-1].set_xticks(np.arange(0, len(features) + noise_cols));\n",
        "    ax[k-1].set_xticklabels([f.replace('_', ' ').title() for f in features] + ['Noise' for _ in range(noise_cols)]);"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importance using Forward Sequential Feature Selector\n",
        "---\n",
        "+ doesnt select k-best features that are correlated to each other\n",
        "- requires model + hyperparameters as input (research)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00074-91001a41-b5d6-4bb4-aa89-2a7897ec22ad",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k_select in range(1,6):\n",
        "    forward_selection = SequentialFeatureSelector(KNeighborsClassifier(n_neighbors=3), n_features_to_select=k_select)\n",
        "    forward_selection.fit(X_select, np.ravel(y_select))\n",
        "    chosen=forward_selection.get_support()\n",
        "    print('-'*10 + f' k = {k_select} ' + '-'*10)\n",
        "    print(np.array(features_noise)[chosen])"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00086-a76a17be-d52b-46f6-b51f-70cc133a89d3",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3213e619",
        "execution_millis": 5005,
        "output_cleared": false,
        "execution_start": 1619002719729,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building KNN-Model\n",
        "\n",
        "For the scope of this project, we first limit ourselves to a basic classifier called `KNN` (*K-Nearest-Neighbors*) algorithm, classifies out-of-sample data by evaluating the label frequency of k-surrounding (mostly measured through *euclidean distance*) neighbors in a n-dimensional space (where n is the number of features).\n",
        "\n",
        "To build the model, we choose the features selected by *K-Best Features* and and train our model using cross-validation of 10 partitions. In that way we get a more robust estimate for the performance of the metric. \n",
        "\n",
        "We will evaluate the final performance on the test-data that was separated in the beginning of this section, to give an estimate of the performance of our model on real-life data."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00072-900e0e6a-2251-4e02-9d77-771007f4cb09",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5,shuffle=False) # define splitting for cross-validation (shuffle=False for reproducable results) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features = ['compactness', 'color_variability', 'luminance_variability']\n",
        "\n",
        "X_dev_selected = X_dev[selected_features]\n",
        "X_dev_sampled_selected = X_dev_sampled[selected_features]\n",
        "\n",
        "X_test_selected = X_test[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA['results'] = pd.DataFrame({'Method': ['No Upsampling (Baseline)', 'Upsample Training Data before CV', 'Upsample within CV']})"
      ]
    },
    {
      "source": [
        "### Base-Performance on Unbalanced Data\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_reports = {'Classifier': [], 'Hyperparameter': [], 'Accuracy': [], 'Precision': [], 'Recall (Sensitivity)': []}\n",
        "\n",
        "params = {'n_neighbors': range(1,6), 'weights': ['distance', 'uniform']}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "grid = GridSearchCV(knn, param_grid=params, cv=kf, \n",
        "                          scoring='recall')\n",
        "\n",
        "grid.fit(X_dev_selected, np.ravel(y_dev))\n",
        "\n",
        "# results\n",
        "recall_val1 = grid.best_score_\n",
        "estimator1 = grid.best_estimator_\n",
        "print(recall_val1)\n",
        "print(estimator1)"
      ]
    },
    {
      "source": [
        "### Performance on Wrongly Upsampled Data\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_reports = {'Classifier': [], 'Hyperparameter': [], 'Accuracy': [], 'Precision': [], 'Recall (Sensitivity)': []}\n",
        "\n",
        "params = {'n_neighbors': range(1,11), 'weights': ['distance', 'uniform']}\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "grid = GridSearchCV(knn, param_grid=params, cv=kf, \n",
        "                          scoring='recall')\n",
        "\n",
        "grid.fit(X_dev_sampled_selected, np.ravel(y_dev_sampled))\n",
        "\n",
        "recall_val2 = grid.best_score_\n",
        "estimator2 = grid.best_estimator_\n",
        "print(recall_val2)\n",
        "print(estimator2)"
      ]
    },
    {
      "source": [
        "### Performance on Correctly Upsampled Data\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_reports = {'Classifier': [], 'Hyperparameter': [], 'Accuracy': [], 'Precision': [], 'Recall (Sensitivity)': []}\n",
        "\n",
        "params = {\n",
        "    'kneighborsclassifier__n_neighbors': range(1, 11), # technicalities\n",
        "    'kneighborsclassifier__weights': ['distance', 'uniform']\n",
        "}\n",
        "\n",
        "pipeline = make_pipeline(SMOTE(random_state=1), \n",
        "                              KNeighborsClassifier())\n",
        "grid = GridSearchCV(pipeline, param_grid=params, cv=kf, scoring='recall',\n",
        "                        return_train_score=True)\n",
        "grid.fit(X_dev_selected, np.ravel(y_dev));\n",
        "\n",
        "recall_val3 = grid.best_score_\n",
        "estimator3 = grid.best_params_\n",
        "print(recall_val3)\n",
        "print(estimator3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA['results'] = pd.concat([DATA['results'], pd.DataFrame({'Recall Score (Validation)': [recall_val1, recall_val2, recall_val3]})], axis=1)\n",
        "DATA['results']"
      ]
    },
    {
      "source": [
        "### Evaluating Final Performance\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best model in each section evaluated by mac(recall)\n",
        "knn_no_upsampling = KNeighborsClassifier(n_neighbors=1) \n",
        "knn_wrong_upsampling = KNeighborsClassifier(n_neighbors=1) \n",
        "knn_correct_upsampling = KNeighborsClassifier(n_neighbors=8) \n",
        "\n",
        "knn_no_upsampling.fit(X_dev_selected, np.ravel(y_dev))\n",
        "knn_wrong_upsampling.fit(X_dev_sampled_selected, np.ravel(y_dev_sampled))\n",
        "knn_correct_upsampling.fit(X_dev_sampled_selected, np.ravel(y_dev_sampled))\n",
        "\n",
        "results = pd.DataFrame({'Method': ['No Upsampling (Base)', 'Upsample Training Set before CV', 'Upsample as part of CV (Pipeline)']})\n",
        "pred1 = knn_no_upsampling.predict(X_test_selected)\n",
        "pred2 = knn_wrong_upsampling.predict(X_test_selected)\n",
        "pred3 = knn_correct_upsampling.predict(X_test_selected)\n",
        "\n",
        "sens1 = recall_score(y_test, pred1)\n",
        "sens2 = recall_score(y_test, pred2)\n",
        "sens3 = recall_score(y_test, pred3)\n",
        "\n",
        "DATA['results'] = pd.concat([DATA['results'], pd.DataFrame({'Recall Score (Test)': [sens1, sens2, sens3]})], axis=1)\n",
        "DATA['results']\n",
        "#print(sens1, sens2, sens3)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00091-47587e16-dcca-4a6f-952c-7ead42e7a28c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7e049a0",
        "execution_millis": 29,
        "output_cleared": false,
        "execution_start": 1619003433493,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TASK 3*\n",
        "# Open Question: How can we make our model more sensitive?\n",
        "\n",
        "---\n",
        "\n",
        "In the previous section we have developed a model that generally performs alright with an accuracy rate of roughly 70%. Inspecting the model's performance close, it however becomes obvious that the model does better at predicting non-lesions compared to lesions. However, in real-world we would rather want to model to be more sensitive to positives, as a false negative (we do not detect cancer) has potentially fatal consequences, whereas a false positive only motivates people do go to a doctor. \n",
        "\n",
        "In this section we are therefore investigating, how we can tweek our model in a way that it gets more sensitive (increasing the 'recall' metric). In order to do so, we need a model, which outputs predictive labeling (ie. gives a probability on the binary label). With such a model, we can adjust the threshold of prediciting positive. This increases sensitivity, knowing that we will also have more false positives."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00013-facea51d-4f84-4003-a25d-67505e0f0718",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "source": [
        "## Model and Feature Selection\n",
        "---\n",
        "\n",
        "We now use the `Random Forest Classifier`, which is a widely used classifier, which allows us to adjust the performance of detecting positives through lowering the threshold for detecting them. We use the same balanced scaled development set to monitor the performance on cross-validated sets and later evaluate the final performance on the spared test-set - one time with the regular threshold of 0.5 and another time with the adjusted one."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100) # initialise random forest classifier\n",
        "\n",
        "rf.fit(X_dev_sampled, y_dev_sampled) # fit on all features and select highest scoring features\n",
        "\n",
        "rf_feature_importance = pd.DataFrame({'Feature': features, 'Importance': rf.feature_importances_})\n",
        "\n",
        "# plot\n",
        "x = sns.barplot(x='Feature', y='Importance', data=rf_feature_importance);\n",
        "x.set_title(\"Feature Importance in Random Forest Classifier\");\n",
        "x.set_xticklabels(x.get_xticklabels(), rotation=90);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_selected_features = ['compactness', 'color_variability', 'average_blue']"
      ]
    },
    {
      "source": [
        "## Train and Evaluate Models\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100) # initialise random forest classifier\n",
        "\n",
        "X_train, y_train = X_dev_sampled[rf_selected_features], np.ravel(y_dev_sampled)\n",
        "\n",
        "rf.fit(X_dev_sampled[rf_selected_features], np.ravel(y_dev_sampled))\n",
        "y_pred = rf.predict(X_test[rf_selected_features])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "labels, counts = np.unique(y_pred, return_counts=True)\n",
        "ax.bar(labels, counts, color='gray'); ax.set_xticks(labels); ax.set_xticklabels(['Non-Melanoma', 'Melanoma']); ax.set_title('Predicted Labels')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.2 # setting the threshold for positive predictions low \n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "rf.fit(X_dev_sampled[rf_selected_features], np.ravel(y_dev_sampled))\n",
        "predicted_proba = rf.predict_proba(X_test[rf_selected_features])\n",
        "y_pred = (predicted_proba [:,1] >= threshold).astype('int')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "labels, counts = np.unique(y_pred, return_counts=True)\n",
        "ax.bar(labels, counts, color='gray'); ax.set_xticks(labels); ax.set_xticklabels(['Non-Melanoma', 'Melanoma']); ax.set_title('Predicted Labels')\n",
        "\n",
        "#y_pred=clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00025-86c4f020-f4de-43e0-88d0-d1f5b1b0874e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00026-bed7848d-d805-47f0-8bf7-523a4cb790f6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00027-65d1e65c-b9c5-4a9a-83da-9c4055f03f8c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00028-64a0d452-fc0a-40c4-a3b2-4d35e7515feb",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00029-c9887334-2738-44bb-90a3-2b94c9240649",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "00030-3232008b-99b3-4ce6-8bb7-627d3c530a81",
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "7810e8fe-98e9-4f91-8d21-605a64b16e29",
    "deepnote": {},
    "deepnote_execution_queue": [],
    "kernelspec": {
      "name": "python383jvsc74a57bd0ce483ef3f3f15830cc71af6662324550274ded09d10a1a693bdaad1eb103022d",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    }
  }
}